#!/usr/bin/env ruby
# frozen_string_literal: true

require 'cgi'
require 'date'
require 'digest'
require 'fileutils'
require 'json'
require 'logger'
require 'net/http'
require 'openssl'
require 'optparse'
require 'ostruct'
require 'pathname'
require 'set'
require 'socket'
require 'uri'
require 'zlib'

# TODO:
# * Allow mapping channel call sign/number combos to custom names, which take
#   preference over any that are auto-detected

# Returns the SHA-512 digest of the given stringified values.
def digest(
  *values, # Array<any>
  format: :hex, # :hex | :base64 | :bubblebabble
  length: 999_999_999 # The maximum length at which to truncate the resulting digest
)
  d = Digest::SHA2.new(512)
  values.each { |v| d.update(v.to_s) }

  hash =
    case format
      when :hex then d.hexdigest
      when :base64 then d.base64digest
      when :bubblebabble then d.bubblebabble
      else
        raise ArgumentError, "Invalid format: #{format.inspect}"
    end

  hash[0...length]
end

PROGRAM_NAME = 'tv_grab_zap2it'
VERSION = Gem::Version.new('0.0.1').freeze
RELEASE =
  begin
    # Compute a truncated SHA-512 digest of the current file and use this as our
    # release identifier. Since the entire program is in a single file, this is
    # guaranteed to provide a unique and stable value for each "build".
    file_data = File.read(Pathname.new(__FILE__).realpath)

    digest(file_data, format: :hex, length: 8)
  end

# Compile the version information into a single string for easy use elsewhere.
VERSION_INFO = "#{PROGRAM_NAME} v#{VERSION} (#{RELEASE})"

# The number of seconds to wait for any given HTTP request to finish.
HTTP_REQUEST_TIMEOUT_SECONDS = 60

XMLTV_DESCRIPTION = 'USA/Canada (zap2it.com)'
XMLTV_CAPABILITIES = %w[baseline cache].freeze

ZAP2IT_API_HOST = 'https://tvlistings.zap2it.com'
RABBITEARS_HOST = 'https://www.rabbitears.info'

# The largest number of days you're allowed to fetch from the API. Apparently,
# also the _only_ number of days you're allowed to fetch...
ZAP2IT_MAXIMUM_DAYS_TO_FETCH = 14

# Rate limit ourselves to this many fetches per second globally so we don't
# overload the local networks or any of the remote APIs we're using.
FETCH_MIN_SECONDS_BETWEEN_REQUESTS = 0.5

# A map of know rating values to their corresponding pictographic icons. The
# icons are sourced from
# https://en.wikipedia.org/wiki/TV_Parental_Guidelines#Ratings.
RATINGS_TO_ICON_URLS =
  begin
    ratings_to_icon_urls = {
      'Y' => 'https://upload.wikimedia.org/wikipedia/commons/thumb/2/25/TV-Y_icon.svg/250px-TV-Y_icon.svg.png',
      'Y7' => 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/5a/TV-Y7_icon.svg/250px-TV-Y7_icon.svg.png',
      'G' => 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/5e/TV-G_icon.svg/250px-TV-G_icon.svg.png',
      'PG' => 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/9a/TV-PG_icon.svg/250px-TV-PG_icon.svg.png',
      '14' => 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c3/TV-14_icon.svg/250px-TV-14_icon.svg.png',
      'MA' => 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/34/TV-MA_icon.svg/250px-TV-MA_icon.svg.png',

      # This is the same as `14`, but we get it in this form instead of just a
      # literal number when no `TV-` prefix is present.
      '14+' => 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c3/TV-14_icon.svg/250px-TV-14_icon.svg.png',
    }

    # Also prefix the ratings with `TV-` since they come to us in both prefixed
    # and "naked" forms.
    ratings_to_icon_urls.to_a.each do |(rating, url)|
      ratings_to_icon_urls["TV-#{rating}"] = url
    end

    ratings_to_icon_urls.freeze
  end

# All the ETSI genre categories we use when mapping zap2it's genres to these
# "proper" ones that are understood by e.g. Kodi and other common software.
#
# All of these values come from Table 28 (page 43) in
# https://www.etsi.org/deliver/etsi_en/300400_300499/300468/01.14.01_60/en_300468v011401p.pdf
ETSI_GENRE_MOVIE_DRAMA = 'Movie/Drama (general)'
ETSI_GENRE_DETECTIVE_TRHILLER = 'Detective/Thriller'
ETSI_GENRE_ADVENTURE_WESTERN_WAR = 'Adventure/Western/War'
ETSI_GENRE_SCIENCE_FICTION_FANTASY_HORROR = 'Science fiction/Fantasy/Horror'
ETSI_GENRE_COMEDY = 'Comedy'
ETSI_GENRE_SOAP_MELODRAMA_FOLKLORIC = 'Soap/Melodrama/Folkloric'
ETSI_GENRE_ROMANCE = 'Romance'
ETSI_GENRE_SERIOUS_CLASSICAL_RELIGIOUS_HISTORICAL_MOVIE_DRAMA = 'Serious/Classical/Religious/Historical movie/Drama'
ETSI_GENRE_ADULT_MOVIE_DRAMA = 'Adult movie/Drama'

ETSI_GENRE_NEWS_CURRENT_AFFAIRS = 'News/Current affairs (general)'
ETSI_GENRE_NEWS_WEATHER_REPORT = 'News/Weather report'
ETSI_GENRE_NEWS_MAGAZINE = 'News magazine'
ETSI_GENRE_DOCUMENTARY = 'Documentary'
ETSI_GENRE_DISCUSSION_INTERVIEW_DEBATE = 'Discussion/Interview/Debate'

ETSI_GENRE_SHOW_GAME_SHOW = 'Show/Game show (general)'
ETSI_GENRE_GAME_SHOW_QUIZ_CONTEST = 'Game show/Quiz/Contest'
ETSI_GENRE_VARIETY_SHOW = 'Variety show'
ETSI_GENRE_TALK_SHOW = 'Talk show'

ETSI_GENRE_SPORTS = 'Sports (general)'
ETSI_GENRE_SPECIAL_EVENTS = 'Special events (Olympic Games, World Cup, etc.)'
ETSI_GENRE_SPORTS_MAGAZINES = 'Sports magazines'
ETSI_GENRE_FOOTBALL_SOCCER = 'Football/Soccer'
ETSI_GENRE_TENNIS_SQUASH = 'Tennis/Squash'
ETSI_GENRE_TEAM_SPORTS_EXCLUDING_FOOTBALL = 'Team sports (excluding football)'
ETSI_GENRE_ATHLETICS = 'Athletics'
ETSI_GENRE_MOTOR_SPORT = 'Motor sport'
ETSI_GENRE_WATER_SPORT = 'Water sport'
ETSI_GENRE_WINTER_SPORTS = 'Winter sports'
ETSI_GENRE_EQUESTRIAN = 'Equestrian'
ETSI_GENRE_MARTIAL_SPORTS = 'Martial sports'

ETSI_GENRE_CHILDRENS_YOUTH_PROGRAMS = "Children's/Youth programmes (general)"
ETSI_GENRE_PRESCHOOL_CHILDRENS_PROGRAMS = "Pre-school children's programmes"
ETSI_GENRE_ENTERTAINMENT_PROGRAMMES_FOR_6_TO_14 = 'Entertainment programmes for 6 to 14'
ETSI_GENRE_ENTERTAINMENT_PROGRAMMES_FOR_10_TO_16 = 'Entertainment programmes for 10 to 16'
ETSI_GENRE_INFORMATIONAL_EDUCATIONAL_SCHOOL_PROGRAMMES = 'Informational/Educational/School programmes'
ETSI_GENRE_CARTOONS_PUPPETS = 'Cartoons/Puppets'

ETSI_GENRE_MUSIC_BALLET_DANCE = 'Music/Ballet/Dance (general)'
ETSI_GENRE_ROCK_POP = 'Rock/Pop'
ETSI_GENRE_SERIOUS_MUSIC_CLASSICAL_MUSIC = 'Serious music/Classical music'
ETSI_GENRE_FOLK_TRADITIONAL_MUSIC = 'Folk/Traditional music'
ETSI_GENRE_JAZZ = 'Jazz'
ETSI_GENRE_MUSICAL_OPERA = 'Musical/Opera'
ETSI_GENRE_BALLET = 'Ballet'

ETSI_GENRE_ARTS_CULTURE_WITHOUT_MUSIC = 'Arts/Culture (without music, general)'
ETSI_GENRE_PERFORMING_ARTS = 'Performing arts'
ETSI_GENRE_FINE_ARTS = 'Fine arts'
ETSI_GENRE_RELIGION = 'Religion'
ETSI_GENRE_POPULAR_CULTURE_TRADITIONAL_ARTS = 'Popular culture/Traditional arts'
ETSI_GENRE_LITERATURE = 'Literature'
ETSI_GENRE_FILM_CINEMA = 'Film/Cinema'
ETSI_GENRE_EXPERIMENTAL_FILM_VIDEO = 'Experimental film/video'
ETSI_GENRE_BROADCASTING_PRESS = 'Broadcasting/Press'
ETSI_GENRE_NEW_MEDIA = 'New media'
ETSI_GENRE_ARTS_CULTURE_MAGAZINES = 'Arts/Culture magazines'
ETSI_GENRE_FASHION = 'Fashion'

ETSI_GENRE_SOCIAL_POLITICAL_ISSUES_ECONOMICS = 'Social/Political issues/Economics (general)'
ETSI_GENRE_MAGAZINES_REPORTS_DOCUMENTARY = 'Magazines/Reports/Documentary'
ETSI_GENRE_ECONOMICS_SOCIAL_ADVISORY = 'Economics/Social advisory'
ETSI_GENRE_REMARKABLE_PEOPLE = 'Remarkable people'

ETSI_GENRE_EDUCATION_SCIENCE_FACTUAL_TOPICS = 'Education/Science/Factual topics (general)'
ETSI_GENRE_NATURE_ANIMALS_ENVIRONMENT = 'Nature/Animals/Environment'
ETSI_GENRE_TECHNOLOGY_NATURAL_SCIENCES = 'Technology/Natural sciences'
ETSI_GENRE_MEDICINE_PHYSIOLOGY_PSYCHOLOGY = 'Medicine/Physiology/Psychology'
ETSI_GENRE_FOREIGN_COUNTRIES_EXPEDITIONS = 'Foreign countries/Expeditions'
ETSI_GENRE_SOCIAL_SPIRITUAL_SCIENCES = 'Social/Spiritual sciences'
ETSI_GENRE_FURTHER_EDUCATION = 'Further education'
ETSI_GENRE_LANGUAGES = 'Languages'

ETSI_GENRE_LEISURE_HOBBIES = 'Leisure hobbies (general)'
ETSI_GENRE_TOURISM_TRAVEL = 'Tourism/Travel'
ETSI_GENRE_HANDICRAFT = 'Handicraft'
ETSI_GENRE_MOTORING = 'Motoring'
ETSI_GENRE_FITNESS_AND_HEALTH = 'Fitness and health'
ETSI_GENRE_COOKING = 'Cooking'
ETSI_GENRE_ADVERISEMENT_SHOPPING = 'Advertisement/Shopping'
ETSI_GENRE_GARDENING = 'Gardening'

ETSI_GENRE_ORIGINAL_LANGUAGE = 'Original language'
ETSI_GENRE_BLACK_AND_WHITE = 'Black and white'
ETSI_GENRE_UNPUBLISHED = 'Unpublished'
ETSI_GENRE_LIVE_BROADCAST = 'Live broadcast'
ETSI_GENRE_PLANOSTEREOSCOPIC = 'Plano-stereoscopic'
ETSI_GENRE_LOCAL_OR_REGIONAL = 'Local or regional'

# Useful time constants for obtaining a number of seconds via multiplication.
class TimeInterval
  SECONDS = 1
  MINUTES = 60 * SECONDS
  HOURS = 60 * MINUTES
  DAYS = 24 * HOURS
  WEEKS = 7 * DAYS
end.freeze

class Color
  BLACK = "\e[30m"
  RED = "\e[31m"
  GREEN = "\e[32m"
  BROWN = "\e[33m"
  BLUE = "\e[34m"
  MAGENTA = "\e[35m"
  CYAN = "\e[36m"
  WHITE = "\e[37m"

  RESET = "\e[0m"
end.freeze

# Used to extract information about a method from an entry in the call stack.
CALLER_INFO_REGEXP = /:(?<line_number>\d+):in\s+`(?<method_name>[^']+)'$/

# Create the global logger for simple use from all places in the program. If
# this is configured further, we do so in `#main!`.
LOG = Logger.new(
  # Always log to STDERR so we don't mess with anything we're otherwise writing
  # to STDOUT. If someone wants to log to a different file, they can redirect
  # our error output to it themselves!
  $stderr,
  # The level we pick here isn't of consequence since we'll override it
  # immediately on running `#main!` with whatever the user configured, or with
  # the default option we selected when generating the config.
  level: :error,

  # Enable nice custom formatting for useful output.
  formatter: proc do |severity, datetime, _program_name, message|
    output_parts = []

    # Only include "fancy" output information at the more verbose log levels
    # since it's expensive to compute.
    if LOG.info?
      severity_letter, severity_color =
        case severity
          when 'DEBUG' then ['D', Color::CYAN]
          when 'INFO' then ['I', Color::WHITE]
          when 'WARN' then ['W', Color::BROWN]
          when 'ERROR' then ['E', Color::RED]
          when 'FATAL' then ['F', Color::MAGENTA]
          when 'UNKNOWN' then ['U', Color::BLUE]
        end

      output_parts << "#{severity_color}#{severity_letter}#{Color::RESET}"
      output_parts << datetime.strftime('%Y%m%d_%H%M%S.%5N')

      log_call_stack = caller(4)
      if caller_info = CALLER_INFO_REGEXP.match(log_call_stack.first)
        output_parts << "#{caller_info[:method_name]}@#{caller_info[:line_number]}"
      end

      output_parts << '--'
    end

    output_parts << message

    output_parts
      .compact
      .join(' ') + "\n"
  end,
)

# A builder-style class for parsing and validating arguments in a standardized
# way.
class Arg
  attr_reader \
    :name,
    :parsers,
    :value

  def initialize(name, parsers, value)
    @name = name
    @parsers = parsers
    @value = value
  end

  # Create a new builder with the given argument name and nothing else.
  def self.name(
    name # String
  )
    unless name.is_a?(String) && !name.empty?
      raise ArgumentError, 'name must be a non-empty string'
    end

    Arg.new(name.strip, [], nil)
  end

  # Add a parser and return a new `Arg` that inherits its other values, but has
  # another parser added to its list.
  def parser(
    &block # (value: typeof prior parser) => any
  )
    Arg.new(
      @name,
      @parsers + [block],
      @value,
    )
  end

  # Ensures that the passed value is an instance of at least one of the given
  # classes using `#is_a?`.
  def is_a(first_class, *other_classes)
    classes = [first_class, *other_classes].freeze
    parser do |value|
      value_is_a = classes.any? do |potential_class|
        value.is_a?(potential_class)
      end

      unless value_is_a
        class_names = classes.map(&:name).join(', ')

        # Don't add "one of" if there's only a single class to check.
        one_of_text =
          if classes.size < 2
            ''
          else
            'one of '
          end

        raise ArgumentError, 
"{{ name }} must be an instance of #{one_of_text}#{class_names}, but was an instance of #{value.class.name}"
      end

      value
    end
  end

  # Ensures the passed value is one of the given values.
  def one_of(potential_value, *other_values)
    potential_values = [potential_value, *other_values].freeze
    parser do |value|
      unless potential_values.include?(value)
        values_text = potential_values.map(&:to_s).join(', ')

        # Don't add "one of" if there's only a single value to check.
        one_of_text =
          if potential_values.empty?
            ' '
          else
            'one of '
          end

        raise ArgumentError, "{{ name }} was expected to be #{one_of_text}#{values_text}, but was #{value}"
      end

      value
    end
  end

  def non_empty
    parser do |value|
      if value.empty?
        raise ArgumentError, '{{ name }} must not be empty'
      end

      value
    end
  end

  # Validates that a value is non-`nil` and returns that value.
  def non_nil
    parser do |value|
      if value.nil?
        raise ArgumentError, '{{ name }} is required to be non-`nil`'
      end

      value
    end
  end

  def strip
    is_a(String).parser do |value|
      value.strip
    end
  end

  def substitute(
    regexp, # Regexp
    substitution # String
  )
    is_a(String).parser do |value|
      value.gsub(regexp, substitution)
    end
  end

  def downcase
    is_a(String).parser do |value|
      value.downcase
    end
  end

  def upcase
    is_a(String).parser do |value|
      value.upcase
    end
  end

  def symbolize
    parser do |value|
      value.to_sym
    end
  end

  def int
    is_a(String).parser do |value|
      
        Integer(value, 10)
      rescue ArgumentError => e
        raise ArgumentError, "{{ name }} of #{value.inspect} is not a valid integer: #{e}"
      
    end
  end

  def time
    is_a(Integer).parser do |value|
      Time.at(value).getutc
    end
  end

  def min(
    n # Integer
  )
    parser do |value|
      if value < n
        raise ArgumentError, "{{ name }} of #{value.inspect} must not be less than #{n}"
      end

      value
    end
  end

  def max(
    n # Integer
  )
    parser do |value|
      if value > n
        raise ArgumentError, "{{ name }} of #{value.inspect} must not be greater than #{n}"
      end

      value
    end
  end

  def path_name
    parser do |value|
      Pathname
        .new(value)
        .cleanpath
        .expand_path
    end
  end

  def exists
    parser.path_name do |value|
      unless value.exist?
        raise ArgumentError, "{{ name }} of #{value} does not exist"
      end
    end
  end

  # Opens an IO stream from the given path name.
  def stream(
    mode = 'r' # https://ruby-doc.org/core-2.7.2/IO.html#method-c-new-label-IO+Open+Mode
  )
    path_name.parser do |path|
      fd = path.sysopen(mode)
      IO.open(fd, mode)
    end
  end

  def uri
    parser do |value|
      URI.parse(value)
    rescue URI::InvalidURIError => e
      raise ArgumentError, "{{ name }} of #{value.inspect} is not a valid URI: #{e}"
    end
  end

  # Thread our value through each configured parser in turn, passing the result
  # of each parser/validator through to the next. Returns the output of the
  # final parser given and sets `.value` to the same.
  #
  # Converts all raised errors into `ArgumentError` instances and re-raises
  # them.
  def parse(
    value # any
  )
    
      @value = @parsers.inject(value) do |current_value, parser|
        parser.call(current_value)
      end
    rescue StandardError => e
      new_err_class = ArgumentError

      # Replace any occurence of `{{ name }}` with our configured name to make
      # the errors prettier.
      message = e.message.gsub(/\{\{\s*name\s*\}\}/i, @name)

      # Preserve the original error class name if it's not the one we're
      # "casting" to.
      if e.class.name != new_err_class.name
        message = "#{e.class.name}: #{message}"
      end

      raise new_err_class, message
    
  end
end

# A simple XML tag container that can form a tree and be printed to a string.
# This handles correct escaping of stringified values, so provide everything "as
# is" and allow this class to handle all escaping for you.
class Xml
  attr_reader \
    :name,
    :attributes,
    :children

  def initialize(
    name, # Symbol | String, with `_` converted to `-` for Symbols
    attributes = {}, # Hash<Symbol | String, any>
    *children # Array<Xml | String | nil>, `nil` and empty string values ommitted
  )
    # We convert `_` to `-` for symbols since writing symbols with hyphens in
    # their names is tedious.
    @name =
      if name.is_a?(Symbol)
        hyphenize_symbol(name)
      else
        name.to_sym
      end

    @attributes = attributes
    @children = children
      .compact
      .reject { |n| n.is_a?(String) && n.empty? }
  end

  # Print this XML tag and all its children to a correctly-escaped and formatted
  # string, something suitable for writing to a file.
  def to_s(
    depth: 0, # Integer
    prev_thing: nil # :tag | :text | nil (`nil` only for very first element)
  )
    attrs_string = @attributes
      .map do |(name, val)|
        name =
          if name.is_a?(Symbol)
            hyphenize_symbol(name)
          else
            name
          end
        " #{name}=\"#{escape_attribute_value(val.to_s)}\""
      end
      .join

    indent = "\t" * depth

    # There's no need to output the children if there are none!
    is_self_closing = @children.count.zero?
    if is_self_closing
      tag = "<#{@name}#{attrs_string} />"
      return "\n" + indent + tag if prev_thing == :tag
        
      
        return tag
      
    end

    # Now, we assemble the output string appropriately.
    parts = []

    if prev_thing == :tag
      parts << "\n"
      parts << indent
    end

    # Add the opening tag, which is a `:tag` for our purposes.
    parts << "<#{@name}#{attrs_string}>"
    prev_thing = :tag

    @children.each do |child|
      next if child.nil?

      if child.is_a?(String)
        parts << escape_text(child)
        prev_thing = :text
      elsif child.is_a?(Xml)
        parts << child.to_s(depth: depth + 1, prev_thing: prev_thing)
        prev_thing = :tag
      else
        raise ArgumentError, "Unknown XML child type: #{child.class}"
      end
    end

    if prev_thing == :tag
      parts << "\n"
      parts << indent
    end

    parts << "</#{@name}>"

    parts.join
  end

  private

  def hyphenize_symbol(
    sym # Symbol
  ) # Symbol
    sym
      .to_s
      .gsub(/_/, '-')
      .to_sym
  end

  # See https://stackoverflow.com/a/1091953 for information about escaping
  # XML strings.
  def escape_text(
    text # String
  ) # String
    text
      .gsub(/&/, '&amp;') # Must come first to prevent double-escaping others!
      .gsub(/</, '&lt;')
  end

  # We print all attributes surrounded by `"`, so we don't escape `'` within
  # attribute text.
  def escape_attribute_value(
    value # String
  ) # String
    value
      .gsub(/&/, '&amp;') # Must come first to prevent double-escaping others!
      .gsub(/"/, '&quot;')
      .gsub(/</, '&lt;')
  end
end

# A provider, something that has a "lineup" associated with it. Typically this
# is something like "Local over-the-air stations" or "AT&T Uverse Cable" or
# something of this nature.
#
# These are only unique given a combination of country, postal code, and
# "headend" id!
class Provider
  attr_reader \
    :country,
    :id,
    :postal_code,
    :name,
    :type

  def initialize(
    country: nil, # Symbol
    id: nil, # String, the `headendId` value from the API
    name: nil, # String
    postal_code: nil, # String
    type: nil # String
  )
    @id = Arg
      .name('id')
      .non_nil
      .is_a(String)
      .non_empty
      .parse(id)

    @name = Arg
      .name('name')
      .non_nil
      .is_a(String)
      .non_empty
      .parse(name)

    @postal_code = Arg
      .name('postal_code')
      .non_nil
      .non_empty
      .is_a(String)
      .parse(postal_code)

    @type = Arg
      .name('type')
      .non_nil
      .is_a(String)
      .non_empty
      .downcase
      .symbolize
      .parse(type)

    @country = Arg
      .name('country')
      .one_of(:USA, :CAN)
      .parse(country)
  end

  def to_s
    name_s =
      if name.nil?
        ''
      else
        "#{name}, "
      end

    "#{name_s}#{country} #{postal_code} (#{id})"
  end
end

# A channel in a lineup.
class Channel
  attr_reader \
    :provider,
    :call_sign,
    :name,
    :id,
    :number,
    :image_url

  def initialize(
    provider: nil, # Provider
    call_sign: nil, # String
    name: nil, # String | nil
    id: nil, # String
    number: nil, # String
    image_url: nil # String
  )
    @provider = Arg
      .name('provider')
      .is_a(Provider)
      .parse(provider)

    @call_sign = Arg
      .name('call_sign')
      .non_nil
      .is_a(String)
      .strip
      .non_empty
      .parse(call_sign)

    # Name is optional.
    @name =
      unless name.nil?
        Arg
          .name('name')
          .is_a(String)
          .strip
          .non_empty
          .parse(name)
      end

    @id = Arg
      .name('id')
      .non_nil
      .is_a(String)
      .strip
      .non_empty
      .parse(id)

    @number = Arg
      .name('number')
      .non_nil
      .is_a(String)
      .strip
      .non_empty
      .parse(number)

    @image_url = Arg
      .name('image_url')
      .non_nil
      .is_a(String)
      .strip
      .uri
      .parser do |uri|
        # The URL comes in "naked" and needs to be secure-ified.
        uri.scheme = 'https'

        # The URL _also_ comes in with `w=123`, but if we strip this off then
        # we'll get back the original, full-size picture instead.
        uri.query = nil

        uri
      end
      .parse(image_url)
  end

  # An RFC-2838 id for this channel.
  def xml_id
    # See https://tools.ietf.org/html/rfc2838 for more information about this id
    # format. Since we can't really determine the actual "owner" of the network,
    # we attribute it to zap2it via their internal id instead.
    "#{id}.zap2it.com"
  end

  def to_xml
    Xml.new(:channel, { id: xml_id }, *[
              Xml.new(:icon, { src: @image_url }),
      @name && Xml.new(:display_name, {}, @name),
      Xml.new(:display_name, {}, "#{@call_sign} (#{@number})"),
      Xml.new(:display_name, {}, @call_sign),
      Xml.new(:display_name, {}, @number),
            ],)
  end

  def to_s
    "#{number} #{call_sign} (#{id})"
  end
end

# One program/timeslot combination in a channel's lineup.
class Program
  attr_reader \
    :channel,
    :series_id,
    :program_id,
    :start_time,
    :end_time,
    :season,
    :episode,
    :title,
    :secondary_title,
    :description,
    :image_url,
    :previously_shown_time,
    :rating,
    :tags,
    :genres,
    :original_release_date,
    :is_movie,
    :credits

  def initialize(
    channel: nil, # Channel
    series_id: nil, # String
    program_id: nil, # String
    start_time: nil, # Time
    end_time: nil, # Time
    season: nil, # Integer | nil
    episode: nil, # Integer | nil
    title: nil, # String
    secondary_title: nil, # String | nil
    description: nil, # String | nil
    image_url: nil, # String
    previously_shown_time: nil, # String | nil
    rating: nil, # String | nil
    tags: nil, # Array<String>
    genres: nil, # Array<String>
    original_release_date: nil, # Time | nil
    is_movie: nil, # Boolean
    is_new: nil, # Boolean
    is_live: nil, # Boolean
    is_premiere: nil, # Boolean
    is_finale: nil, # Boolean
    is_generic: nil, # Boolean
    credits: nil # Array<Credit info hash>
  )
    @channel = Arg
      .name('channel')
      .is_a(Channel)
      .parse(channel)

    @series_id = Arg
      .name('series_id')
      .is_a(String)
      .strip
      .non_empty
      .parse(series_id)

    @program_id = Arg
      .name('program_id')
      .is_a(String)
      .strip
      .non_empty
      .parse(program_id)

    @start_time = Arg
      .name('start_time')
      .is_a(Time)
      .parse(start_time)

    @end_time = Arg
      .name('end_time')
      .is_a(Time)
      .parser do |t|
        unless t > @start_time
          raise ArgumentError, '{{ name }} must be later than start_time'
        end

        t
      end
      .parse(end_time)

    @season =
      unless season.nil?
        Arg
          .name('season')
          .is_a(Integer)
          .min(1)
          .parse(season)
      end

    @episode =
      unless episode.nil?
        Arg
          .name('episode')
          .is_a(Integer)
          .min(0) # We allow zero since this can indicate "special" episodes.
          .parse(episode)
      end

    @title = Arg
      .name('title')
      .is_a(String)
      .strip
      .non_empty
      .parse(title)

    @secondary_title =
      unless secondary_title.nil?
        Arg
          .name('secondary_title')
          .is_a(String)
          .strip
          .non_empty
          .parse(secondary_title)
      end

    @description =
      unless description.nil?
        Arg
          .name('description')
          .is_a(String)
          .strip
          .non_empty
          .parse(description)
      end

    @image_url = Arg
      .name('image_url')
      .non_nil
      .is_a(String)
      .strip
      .uri
      .parse(image_url)

    @previously_shown_time =
      unless previously_shown_time.nil?
        Arg
          .name('previously_shown_time')
          .is_a(Time)
          .parse(previously_shown_time)
      end

    @rating =
      unless rating.nil?
        Arg
          .name('rating')
          .is_a(String)
          .strip
          .non_empty
          .parse(rating)
      end

    @original_release_date =
      unless original_release_date.nil?
        Arg
          .name('original_release_date')
          .is_a(Time)
          .parse(original_release_date)
      end

    @is_movie = Arg
      .name('is_movie')
      .one_of(true, false)
      .parse(is_movie)

    @is_new = Arg
      .name('is_new')
      .one_of(true, false)
      .parse(is_new)

    @is_live = Arg
      .name('is_live')
      .one_of(true, false)
      .parse(is_live)

    @is_premiere = Arg
      .name('is_premiere')
      .one_of(true, false)
      .parse(is_premiere)

    @is_finale = Arg
      .name('is_finale')
      .one_of(true, false)
      .parse(is_finale)

    @is_generic = Arg
      .name('is_generic')
      .one_of(true, false)
      .parse(is_generic)

    # TODO: Validate these more thoroughly!
    @tags = Arg
      .name('tags')
      .is_a(Array)
      .parse(tags)

    # TODO: Validate these more thoroughly!
    @genres = Arg
      .name('genres')
      .is_a(Array)
      .parse(genres)

    # TODO: Validate these more thoroughly!
    @credits = Arg
      .name('credits')
      .is_a(Array)
      .parse(credits)
  end

  def movie?; 
    @is_movie; 
  end
  def new?; 
    @is_new; 
  end
  def live?; 
    @is_live; 
  end
  def premiere?; 
    @is_premiere; 
  end
  def finale?; 
    @is_finale; 
  end
  def generic?; 
    @is_generic; 
  end

  def to_xml
    attrs = {
      start: format_xmltv_time(@start_time),
      stop: format_xmltv_time(@end_time),
      channel: @channel.xml_id,
    }

    children = []

    if @image_url
      children << Xml.new(:icon, { src: @image_url })
    end

    if @season && @episode
      # Add the `xmltv_ns` episode information as this seems to be treated as
      # "most authoritative" by e.g. Kodi.
      xmltvns_episode = [
        (@season - 1).to_s,
        '.',
        (@episode - 1).to_s,
        '.',
      ].join
      children << Xml.new(:episode_num, { system: :xmltv_ns }, xmltvns_episode)

      # Use a more human-friendly format as well, i.e. something like S01E02.
      onscreen_episode =
        [
          "S#{@season.to_s.rjust(2, '0')}",
          "E#{@episode.to_s.rjust(2, '0')}",
        ].join
      children << Xml.new(:episode_num, { system: :onscreen }, onscreen_episode)
    end

    children << Xml.new(:title, { lang: :en }, @title)
    if @secondary_title
      children << Xml.new(:sub_title, { lang: :en }, @secondary_title)
    end

    original_release_date_format =
      if movie?
        '%Y'
      else
        '%Y-%m-%d'
      end
    if @original_release_date
      # Movie release dates are only precise to the year, while television shows
      # are precise to the day; this is just how the data comes to us!
      children << Xml.new(:date, {}, @original_release_date.strftime(original_release_date_format))
    end

    children << rating_xml

    # Movies are a very distinctive category, so they get the appropriate tag
    # _first_ to define it as "most canonical".
    if movie?
      children << Xml.new(:category, { lang: :en }, ETSI_GENRE_MOVIE_DRAMA)
    end

    # Add a special category for live broadcasts since such a category exists.
    if live?
      children << Xml.new(:category, { lang: :en }, ETSI_GENRE_LIVE_BROADCAST)
    end

    # "Convert" all the original genre values into ETSI values, then combine
    # them with the originals (mapped values taking precedence) and add them to
    # the output as categories.
    mapped_genres = @genres
      .flat_map { |original_genre| map_genre(original_genre) }
      .uniq
    [*mapped_genres, *@genres]
      .uniq
      .each do |category_text|
        children << Xml.new(:category, { lang: :en }, category_text)
      end

    # Include both tags as categories since it makes sense to be able to filter
    # by these as well as genres, e.g. for queries like "HDTV Sports".
    @tags.each do |category_text|
      children << Xml.new(:category, { lang: :en }, category_text)
    end

    # Include any credits.
    unless @credits.empty?
      credits_xml = Xml.new(:credits, {}, *@credits.map do |credit|
        type, name, role = credit.fetch_values(:type, :name, :role)
        credits_attrs = {}

        # Add the `role` attribute, i.e. who they played, for actors whenever
        # possible.
        role = credit.fetch(:role)
        if type == :actor && !role.nil?
          credits_attrs[:role] = role
        end

        Xml.new(type, credits_attrs, name)
      end,)

      children << credits_xml
    end

    # Include the description tag last since it messes up pretty printing as
    # it contains raw text.
    if @description
      # Add "bonus" info into the description, e.g. original air date,
      # season/episode info, "New", etc.
      tags_text_parts = []
      tags_text_parts << 'Finale' if finale?
      tags_text_parts << 'Premiere' if premiere?
      tags_text_parts << 'Live' if live?
      tags_text_parts << 'New' if new?
      tags_text = tags_text_parts.join(', ')

      season_text_parts = []
      season_text_parts << "Season #{@season}" if @season
      season_text_parts << "Episode #{@episode}" if @episode && @episode > 0
      season_text = season_text_parts
        .compact
        .join(', ')

      original_release_date_text =
        if @original_release_date
          date_string = @original_release_date.strftime(original_release_date_format)

          if movie?
            "Released #{date_string}"
          else
            "First aired #{date_string}"
          end
        end

      bonus_text =
        [
          tags_text,
          season_text,
          original_release_date_text,
        ]
          .compact
          .map(&:strip)
          .reject(&:empty?)
          .join(' · ')

      children << Xml.new(
        :desc,
        { lang: :en },
        "#{bonus_text}\n#{@description}".strip,
      )
    end

    children << Xml.new(:last_chance) if finale?
    children << Xml.new(:new) if new?
    children << Xml.new(:premiere) if premiere?

    Xml.new(:programme, attrs, *children)
  end

  # Takes one of the genres from the zap2it API and attempts to map it onto one
  # of the "standard" genres from Table 28 of
  # https://www.etsi.org/deliver/etsi_en/300400_300499/300468/01.14.01_60/en_300468v011401p.pdf.
  #
  # We do this since most things that interact with XMLTV data, including Kodi,
  # only respect and/or know about these ETSI genre values and will ignore all
  # the other ones.
  #
  # Note that this isn't and _can't_ be a 1-1 mapping, so we return both general
  # and specific categories for the given genre along with the original genre
  # itself. The values are returned in order from "most specific" to "least
  # specific", where we treat the original value as "least specific" since it
  # doesn't map well into anything else.
  def map_genre(
    original_genre # String
  ) # Array<String>
    genre_map = {
      # Movie/Drama
      # NOTE: We don't include the general "Movie/Drama" category here since
      # it's rather specific and should only apply to _actual movies_, not
      # random TV shows and such.
      'Action' => [ETSI_GENRE_ADVENTURE_WESTERN_WAR],
      'Adventure' => [ETSI_GENRE_ADVENTURE_WESTERN_WAR],
      'Comedy' => [ETSI_GENRE_COMEDY],
      'Comedy drama' => [ETSI_GENRE_COMEDY, ETSI_GENRE_SERIOUS_CLASSICAL_RELIGIOUS_HISTORICAL_MOVIE_DRAMA],
      'Drama' => [ETSI_GENRE_SERIOUS_CLASSICAL_RELIGIOUS_HISTORICAL_MOVIE_DRAMA],
      'Fantasy' => [ETSI_GENRE_SCIENCE_FICTION_FANTASY_HORROR],
      'Historical drama' => [ETSI_GENRE_SERIOUS_CLASSICAL_RELIGIOUS_HISTORICAL_MOVIE_DRAMA],
      'Horror' => [ETSI_GENRE_SCIENCE_FICTION_FANTASY_HORROR],
      'Mystery' => [ETSI_GENRE_SCIENCE_FICTION_FANTASY_HORROR],
      'Romance' => [ETSI_GENRE_ROMANCE],
      'Romantic comedy' => [ETSI_GENRE_COMEDY, ETSI_GENRE_ROMANCE],
      'Science fiction' => [ETSI_GENRE_SCIENCE_FICTION_FANTASY_HORROR],
      'Soap' => [ETSI_GENRE_SOAP_MELODRAMA_FOLKLORIC],
      'Thriller' => [ETSI_GENRE_SCIENCE_FICTION_FANTASY_HORROR],
      'War' => [ETSI_GENRE_ADVENTURE_WESTERN_WAR],
      'Western' => [ETSI_GENRE_ADVENTURE_WESTERN_WAR],

      # News/Current affairs
      'Documentary' => [ETSI_GENRE_NEWS_CURRENT_AFFAIRS, ETSI_GENRE_DOCUMENTARY],
      'Interview' => [ETSI_GENRE_NEWS_CURRENT_AFFAIRS, ETSI_GENRE_DISCUSSION_INTERVIEW_DEBATE],
      'News' => [ETSI_GENRE_NEWS_CURRENT_AFFAIRS, ETSI_GENRE_NEWS_WEATHER_REPORT],
      'Newsmagazine' => [ETSI_GENRE_NEWS_CURRENT_AFFAIRS, ETSI_GENRE_NEWS_MAGAZINE],
      'Politics' => [ETSI_GENRE_NEWS_CURRENT_AFFAIRS, ETSI_GENRE_DISCUSSION_INTERVIEW_DEBATE],
      'Public affairs' => [ETSI_GENRE_NEWS_CURRENT_AFFAIRS, ETSI_GENRE_DISCUSSION_INTERVIEW_DEBATE],
      'Weather' => [ETSI_GENRE_NEWS_CURRENT_AFFAIRS, ETSI_GENRE_NEWS_WEATHER_REPORT],

      # Show/Game show
      'Entertainment' => [ETSI_GENRE_SHOW_GAME_SHOW, ETSI_GENRE_VARIETY_SHOW],
      'Game show' => [ETSI_GENRE_SHOW_GAME_SHOW, ETSI_GENRE_GAME_SHOW_QUIZ_CONTEST],
      'Reality' => [ETSI_GENRE_SHOW_GAME_SHOW, ETSI_GENRE_VARIETY_SHOW],
      'Talk' => [ETSI_GENRE_SHOW_GAME_SHOW, ETSI_GENRE_TALK_SHOW],
      'Variety' => [ETSI_GENRE_SHOW_GAME_SHOW, ETSI_GENRE_VARIETY_SHOW],
      'Sports talk' => [ETSI_GENRE_SHOW_GAME_SHOW, ETSI_GENRE_TALK_SHOW, ETSI_GENRE_SPORTS],
      'Standup' => [ETSI_GENRE_SHOW_GAME_SHOW, ETSI_GENRE_COMEDY],
      'Sitcom' => [ETSI_GENRE_SHOW_GAME_SHOW, ETSI_GENRE_COMEDY],

      # Sports
      'Action sports' => [ETSI_GENRE_SPORTS],
      'Alpine skiing' => [ETSI_GENRE_SPORTS, ETSI_GENRE_WINTER_SPORTS],
      'Auto racing' => [ETSI_GENRE_SPORTS, ETSI_GENRE_MOTOR_SPORT],
      'Baseball' => [ETSI_GENRE_SPORTS, ETSI_GENRE_TEAM_SPORTS_EXCLUDING_FOOTBALL],
      'Basketball' => [ETSI_GENRE_SPORTS, ETSI_GENRE_TEAM_SPORTS_EXCLUDING_FOOTBALL],
      'Bowling' => [ETSI_GENRE_SPORTS],
      'Boxing' => [ETSI_GENRE_SPORTS, ETSI_GENRE_MARTIAL_SPORTS],
      'Bull riding' => [ETSI_GENRE_SPORTS],
      'Figure skating' => [ETSI_GENRE_SPORTS, ETSI_GENRE_WINTER_SPORTS],
      'Football' => [ETSI_GENRE_SPORTS, ETSI_GENRE_TEAM_SPORTS_EXCLUDING_FOOTBALL],
      'Intl soccer' => [ETSI_GENRE_SPORTS, ETSI_GENRE_FOOTBALL_SOCCER],
      'Mixed martial arts' => [ETSI_GENRE_SPORTS, ETSI_GENRE_MARTIAL_SPORTS],
      'Motorcycle racing' => [ETSI_GENRE_SPORTS, ETSI_GENRE_MOTOR_SPORT],
      'Multi-sport event' => [ETSI_GENRE_SPORTS, ETSI_GENRE_SPECIAL_EVENTS],
      'Pro wrestling' => [ETSI_GENRE_SPORTS, ETSI_GENRE_MARTIAL_SPORTS],
      'Sailing' => [ETSI_GENRE_SPORTS, ETSI_GENRE_WATER_SPORT],
      'Soccer' => [ETSI_GENRE_SPORTS, ETSI_GENRE_FOOTBALL_SOCCER],
      'Surfing' => [ETSI_GENRE_SPORTS, ETSI_GENRE_WATER_SPORT],
      'Triathlon' => [ETSI_GENRE_SPORTS, ETSI_GENRE_ATHLETICS],
      'Watersports' => [ETSI_GENRE_SPORTS, ETSI_GENRE_WATER_SPORT],
      'Wrestling' => [ETSI_GENRE_SPORTS, ETSI_GENRE_MARTIAL_SPORTS],
      'Yacht racing' => [ETSI_GENRE_SPORTS, ETSI_GENRE_WATER_SPORT],
      'eSports' => [ETSI_GENRE_SPORTS],

      # Children's/Youth programmes
      'Children' => [ETSI_GENRE_CHILDRENS_YOUTH_PROGRAMS],

      # Music/Ballet/Dance
      'Dance' => [ETSI_GENRE_MUSIC_BALLET_DANCE],
      'Music' => [ETSI_GENRE_MUSIC_BALLET_DANCE],
      'Musical' => [ETSI_GENRE_MUSIC_BALLET_DANCE],

      # Arts/Culture (without music)
      'Anthology' => [ETSI_GENRE_ARTS_CULTURE_WITHOUT_MUSIC],
      'Art' => [ETSI_GENRE_ARTS_CULTURE_WITHOUT_MUSIC, ETSI_GENRE_FINE_ARTS],
      'Awards' => [ETSI_GENRE_ARTS_CULTURE_WITHOUT_MUSIC, ETSI_GENRE_POPULAR_CULTURE_TRADITIONAL_ARTS],
      'Dog show' => [ETSI_GENRE_ARTS_CULTURE_WITHOUT_MUSIC],
      'Fashion' => [ETSI_GENRE_ARTS_CULTURE_WITHOUT_MUSIC, ETSI_GENRE_FASHION],
      'Parade' => [ETSI_GENRE_ARTS_CULTURE_WITHOUT_MUSIC],
      'Performing arts' => [ETSI_GENRE_ARTS_CULTURE_WITHOUT_MUSIC, ETSI_GENRE_PERFORMING_ARTS],
      'Religious' => [ETSI_GENRE_ARTS_CULTURE_WITHOUT_MUSIC, ETSI_GENRE_RELIGION],

      # Social/Political issues/Economics
      'Biography' => [ETSI_GENRE_SOCIAL_POLITICAL_ISSUES_ECONOMICS, ETSI_GENRE_REMARKABLE_PEOPLE],
      'Bus./financial' => [ETSI_GENRE_SOCIAL_POLITICAL_ISSUES_ECONOMICS, ETSI_GENRE_ECONOMICS_SOCIAL_ADVISORY],
      'Community' => [ETSI_GENRE_SOCIAL_POLITICAL_ISSUES_ECONOMICS],
      'Crime' => [ETSI_GENRE_SOCIAL_POLITICAL_ISSUES_ECONOMICS],
      'Crime drama' => [ETSI_GENRE_SOCIAL_POLITICAL_ISSUES_ECONOMICS],
      'Gay/lesbian' => [ETSI_GENRE_SOCIAL_POLITICAL_ISSUES_ECONOMICS],

      # Education/Science/Factual topics
      'Agriculture' => [ETSI_GENRE_EDUCATION_SCIENCE_FACTUAL_TOPICS, ETSI_GENRE_TECHNOLOGY_NATURAL_SCIENCES],
      'American history' => [ETSI_GENRE_EDUCATION_SCIENCE_FACTUAL_TOPICS],
      'Ancient history' => [ETSI_GENRE_EDUCATION_SCIENCE_FACTUAL_TOPICS],
      'Animals' => [ETSI_GENRE_EDUCATION_SCIENCE_FACTUAL_TOPICS, ETSI_GENRE_NATURE_ANIMALS_ENVIRONMENT],
      'Aviation' => [ETSI_GENRE_EDUCATION_SCIENCE_FACTUAL_TOPICS],
      'EI' => [ETSI_GENRE_EDUCATION_SCIENCE_FACTUAL_TOPICS],
      'Educational' => [ETSI_GENRE_EDUCATION_SCIENCE_FACTUAL_TOPICS],
      'Environment' => [ETSI_GENRE_EDUCATION_SCIENCE_FACTUAL_TOPICS, ETSI_GENRE_NATURE_ANIMALS_ENVIRONMENT],
      'History' => [ETSI_GENRE_EDUCATION_SCIENCE_FACTUAL_TOPICS],
      'How-to' => [ETSI_GENRE_EDUCATION_SCIENCE_FACTUAL_TOPICS, ETSI_GENRE_FURTHER_EDUCATION],
      'Law' => [ETSI_GENRE_EDUCATION_SCIENCE_FACTUAL_TOPICS],
      'Medical' => [ETSI_GENRE_EDUCATION_SCIENCE_FACTUAL_TOPICS, ETSI_GENRE_MEDICINE_PHYSIOLOGY_PSYCHOLOGY],
      'Military' => [ETSI_GENRE_EDUCATION_SCIENCE_FACTUAL_TOPICS],
      'Nature' => [ETSI_GENRE_EDUCATION_SCIENCE_FACTUAL_TOPICS, ETSI_GENRE_NATURE_ANIMALS_ENVIRONMENT],
      'Paranormal' => [ETSI_GENRE_EDUCATION_SCIENCE_FACTUAL_TOPICS, ETSI_GENRE_MEDICINE_PHYSIOLOGY_PSYCHOLOGY],
      'Science' => [ETSI_GENRE_EDUCATION_SCIENCE_FACTUAL_TOPICS],
      'Self improvement' => [ETSI_GENRE_EDUCATION_SCIENCE_FACTUAL_TOPICS],
      'Technology' => [ETSI_GENRE_EDUCATION_SCIENCE_FACTUAL_TOPICS, ETSI_GENRE_TECHNOLOGY_NATURAL_SCIENCES],

      # Leisure hobbies
      'Arts/crafts' => [ETSI_GENRE_LEISURE_HOBBIES, ETSI_GENRE_HANDICRAFT],
      'Auction' => [ETSI_GENRE_LEISURE_HOBBIES, ETSI_GENRE_ADVERISEMENT_SHOPPING],
      'Auto' => [ETSI_GENRE_LEISURE_HOBBIES, ETSI_GENRE_MOTORING],
      'Card games' => [ETSI_GENRE_LEISURE_HOBBIES],
      'Collectibles' => [ETSI_GENRE_LEISURE_HOBBIES],
      'Consumer' => [ETSI_GENRE_LEISURE_HOBBIES, ETSI_GENRE_ADVERISEMENT_SHOPPING],
      'Cooking' => [ETSI_GENRE_LEISURE_HOBBIES, ETSI_GENRE_COOKING],
      'Exercise' => [ETSI_GENRE_LEISURE_HOBBIES, ETSI_GENRE_FITNESS_AND_HEALTH],
      'Fishing' => [ETSI_GENRE_LEISURE_HOBBIES],
      'Gaming' => [ETSI_GENRE_LEISURE_HOBBIES],
      'Health' => [ETSI_GENRE_LEISURE_HOBBIES, ETSI_GENRE_FITNESS_AND_HEALTH],
      'Holiday' => [ETSI_GENRE_LEISURE_HOBBIES],
      'Home improvement' => [ETSI_GENRE_LEISURE_HOBBIES, ETSI_GENRE_HANDICRAFT],
      'House/garden' => [ETSI_GENRE_LEISURE_HOBBIES, ETSI_GENRE_GARDENING],
      'Outdoors' => [ETSI_GENRE_LEISURE_HOBBIES],
      'Poker' => [ETSI_GENRE_LEISURE_HOBBIES],
      'Shopping' => [ETSI_GENRE_LEISURE_HOBBIES, ETSI_GENRE_ADVERISEMENT_SHOPPING],
      'Travel' => [ETSI_GENRE_LEISURE_HOBBIES, ETSI_GENRE_TOURISM_TRAVEL],
    }

    genre_map.fetch(original_genre, original_genre)
  end

  # If a rating is present, returns an XMLTV tag representing it. Otherwise,
  # returns `nil`.
  def rating_xml # Xml | nil
    return nil if rating.nil?

    attributes = {}
    children = [
      # The rating is always included as the value of the overall tag.
      Xml.new(:value, {}, @rating),
    ]

    # If the rating is one of the "standard" US FCC values, include an `icon`
    # tag for it and identify it as such.
    if RATINGS_TO_ICON_URLS.include?(@rating)
      attributes[:system] = 'TV parental guidelines'
      children << Xml.new(:icon, {}, RATINGS_TO_ICON_URLS[@rating])
    end

    Xml.new(:rating, attributes, *children)
  end

  private

  # Format time in the way the XMLTV specification desires.
  def format_xmltv_time(
    t # Time
  ) # String
    t.strftime('%Y%m%d%H%M%S %z')
  end
end

# A config-specific struct that allows for easy access to arbitrary values while
# also providing some helper methods that we use elsewhere.
class Config < OpenStruct
  # Require that the given configuration value be present in the parsed
  # configuration, then return it if present.
  def require(
    key, # Symbol
    name = nil # String, defaults to being auto-generated from `key`
  ) # typeof self[key]
    # "Humanize" the config key if an explicit name wasn't given.
    if name.nil?
      name = key
        .to_s
        .gsub(/_+/, ' ')
        .strip
    end

    value = self[key]

    if value.nil?
      article_text =
        if /^[aeiou]/.match?(name)
          'An'
        else
          'A'
        end
      raise ArgumentError, "#{article_text} #{name} is required but was not specified; see --help for details."
    end

    value
  end

  # Pretty-print our configuration for ease of logging.
  def to_s
    "Config(\n" + each_pair.map do |(key, value)|
      # Omit certian gigantic and not-terribly-useful keys.
      if %i[option_parser cache].include?(key)
        next nil
      end

      "  #{key.inspect} => #{value.inspect}"
    end.compact.join("\n") + "\n)"
  end
end

# A simple cache, either in-memory or backed by a file. All cached values are
# converted to symbolized JSON hashes/arrays.
class Cache
  attr_reader \
    :path

  # Reads existing values from the given path, if any, otherwise uses a
  # memory-only backing store.
  def initialize(
    path = nil # Pathname | nil
  )
    @path = path
    @is_dirty = false

    # Initialize the cache from the backing store, if given.
    @cache = {}
    return unless !path.nil? && path.exist?
      LOG.debug("Attempting to initialize cache data from #{path}")
      @cache = load_cache(path)
      LOG.info("Successfully initialized cache from #{path}")
    
  end

  # Returns the number of entries in the cache.
  #
  # Note that this count includes expired entries that haven't yet been pruned!
  def size
    @cache.size
  end

  # Returns whether the cache has been modified since being loaded.
  def dirty?
    @is_dirty
  end

  # Write the cache to the originally-configured path, if any. If no path was
  # originally configured, does nothing.
  def persist! # self
    # If we were given no path, we can't persist the cache.
    if @path.nil?
      LOG.debug('Unable to persist in-memory cache')
      return
    end

    # If we're not dirty, i.e. if the cache hasn't been modified, do nothing to
    # save loads of time. While this will leave "dirty" entries in the cache,
    # it's still better than having to re-persist the possibly very large cache
    # if nothing has actually changed!
    unless dirty?
      LOG.debug('Declining to persist unmodified (i.e. not dirty) cache')
      return
    end

    # Remove expired values from the cache prior to dumping it so we won't waste
    # time and space storing and serializing expired entries.
    prune!

    # Sometimes, we end up getting errors when reading the cache that suggest
    # the cache was corrupted during write for some reason. E.g.
    # ```
    # Unable to load cache at /var/lib/tvheadend/.hts/tvheadend/epggrab/cache.json.gz: unexpected end of string
    # ```
    #
    # Since it's not entirely clear why this happens, we do the following in an
    # attempt to prevent corrupting the cache on write:
    # 1. Persist to a temporary file first
    # 2. Ensure we can successfully re-load/parse that file
    # 3. If we can load it, replace the original cache file with the new one
    #    using `mv`
    # 4. If we can't load the file, log an error and leave the old cache in
    #    place
    # This hopefully makes cache updates atomic and prevents us from storing any
    # self-corrupted cache data.

    temp_path = path.sub_ext('.tmp')

    LOG.debug("Persisting cache to temporary path #{temp_path}")
    temp_path.open('wb') do |f|
      # Since we control the cache structure, we know it's non-circular.
      json_text = JSON.fast_generate(@cache)

      LOG.debug("Stringified cache JSON is #{json_text.bytesize} bytes")

      # GZip the data heavily since it can get quite large (100Mb or more!) and
      # compresses very well since it's mostly JSON and contains a lot of
      # human-generated text (HTML pages, plot summaries, etc.).
      compressed_json_text = Zlib.gzip(json_text, level: Zlib::BEST_COMPRESSION)

      LOG.debug do
        "Compressed cache JSON string is #{compressed_json_text.bytesize} bytes, #{100.0 * compressed_json_text.bytesize / json_text.bytesize}% of original size"
      end

      f.write(compressed_json_text)
    end

    # Attempt to load the just-written temporary cache; if we can do so
    # successfully, we replace the original cache file with it.
    begin
      LOG.debug('Validating persisted temporary cache')
      # Attempt to re-load (thereby lightly validating) the cache.
      load_cache(temp_path)

      # Move the temporary cache file to its final destination, overwriting the
      # original cache file.
      LOG.debug("Temporary cache at #{temp_path} is valid, moving it to #{@path}")
      FileUtils.mv(temp_path, @path, force: true)

      # Once the cache has been persisted, it's no longer considered "dirty"
      # since it hasn't changed since the last write to disk.
      LOG.debug('Marking persisted cache as non-dirty')
      @is_dirty = false
    rescue StandardError => e
      LOG.error("Failed to successfully re-load persisted temporary cache at #{temp_path} (#{e}); allowing original cache data at #{@path} to remain to avoid writing a corrupted cache")
    end

    self
  end

  # Prunes all currently-expired entries from the cache.
  def prune! # self
    now = Time.now.getutc

    @cache.each_pair do |key, entry|
      next unless entry_expired?(entry, now: now)
      LOG.debug do
        "Pruning entry for key #{key} from cache (expired as of #{entry_expiration_time(entry, 
now: now)}) and marking cache as dirty"
      end

      # Only mark the cache as dirty if something is actually pruned from it.
      @is_dirty = true
      @cache.delete(key)
    end

    self
  end

  # Retrieves the given key from the cache if present, returning `nil` if not
  # present.
  def get(
    cache_key, # String | Symbol
    now: Time.now.getutc # Time
  )
    cache_key = cache_key.to_sym

    # If the entry has expired, delete it from the cache entirely and return
    # `nil`.
    entry = @cache[cache_key]
    if entry.nil?
      nil
    elsif entry_expired?(entry, now: now)
      # If we're expiring an entry, we've modified the cache and it should be
      # re-persisted.
      @is_dirty = true
      @cache.delete(cache_key)
      nil
    else
      entry.fetch(:value)
    end
  end

  # Adds the given key/value to the cache, overwriting any existing one. Returns
  # the value.
  def set(
    cache_key, # String | Symbol,
    value, # JSON
    ttl_seconds, # Integer
    now: Time.now.getutc # Time
  ) # typeof value
    # Since something is being updated, mark the cache as "dirty" so we'll know
    # to actually persist it if asked.
    @is_dirty = true

    Arg
      .name('ttl_seconds')
      .is_a(Integer)
      .min(1)
      .parse(ttl_seconds)
    cache_key = cache_key.to_sym

    @cache[cache_key] = {
      created_at: now.to_i,
      ttl_seconds: ttl_seconds,
      value: value,
    }

    value
  end

  # Load a JSON value from the cache. If no value is found, the given block is
  # run and the resulting value is stored in the cache under the given key
  # before being returned.
  def fetch(
    cache_key, # String | Symbol
    ttl_seconds, # Integer # () => JSON
  ) # the cached value
    Arg
      .name('ttl_seconds')
      .is_a(Integer)
      .min(1)
      .parse(ttl_seconds)

    # Return the value directly if it's already cached.
    now = Time.now.getutc
    value = get(cache_key, now: now)
    return value unless value.nil?

    # If not already cached, run the block and set the cache to the new value,
    # then return the new value.
    set(cache_key, yield, ttl_seconds, now: now)
  end

  private

  def entry_expiration_time(
    entry, # Cache entry hash
    now: Time.now.getutc # Time
  )
    Time.at(entry.fetch(:created_at) + entry.fetch(:ttl_seconds)).getutc
  end

  def entry_expired?(
    entry, # Cache entry hash
    now: Time.now.getutc # Time
  )
    now > entry_expiration_time(entry, now: now)
  end

  def load_cache(
    path # Path
  ) # Cache Hash
    LOG.debug("Attempting to load cache data from #{path}")

    raise ArgumentError, 'Cache path may not be `nil`' if path.nil?
    raise IOError, "File at cache path #{path} does not exist" unless path.exist?

    cache =
      begin
        LOG.debug('Opening cache file...')
        cache = path.open('rb') do |f|
          LOG.debug('Reading cache data...')
          compressed_json_text = f.read

          # The data is stored GZipped, so we must decompress it before parsing
          # the JSON data contained within.
          LOG.debug("Decompressing #{compressed_json_text.bytesize} of compressed cache data...")
          json_text = Zlib.gunzip(compressed_json_text)

          # We use `JSON#parse` instead of `JSON#load` so we don't have to trust
          # the input file we were given, which the documentation suggests we
          # must do if using `JSON#load`.
          LOG.debug("Parsing #{json_text.bytesize} of decompressed cache data...")
          JSON.parse(json_text, symbolize_names: true)
        end
      rescue StandardError => e
        raise IOError, "Unable to load cache at #{path}: #{e}"
      end

    # Do a simple sanity check on the cache format to be sure it's at least the
    # correct top-level type.
    unless cache.is_a?(Hash)
      raise IOError, "#{path} contains invalid cache file contents"
    end

    cache
  end
end

# Returns a new `Time` truncated to the given unit and converted to UTC.
def truncate_time(
  time, # Time
  unit # Integer seconds, e.g. 3600 for an hour or 86400 for a day
) # Time
  (time - (time.to_i % unit)).getutc
end

# Parse the configuration from the command line options.
def parse_config_from_args(
  args # An arguments array, typically `ARGV`.
)
  config = Config.new({
    # The `OptionParser` instance that parsed this config. This is useful so
    # whoever gets the config can inspect e.g. all the parsed arguments that
    # created it.
                        option_parser: nil, # OptionParser | nil

    # These `return_*?` options indicate that the program should run in the
    # requisite "mode" and do something, then exit.

    # Generic hacks for better `--help` output
    return_help_text?: false,
    return_version_info?: false,

    # XMLTV-specific
    return_capabilities?: false,
    return_description?: false,

    # Program-specific
    return_providers?: false,
    return_channels?: false,
    return_lineup?: false,

    # XMLTV-specific configuration, mostly optional.
    cache: Cache.new, # Cache, in-memory by default
    day_offset: 0, # Integer
    days_to_fetch: ZAP2IT_MAXIMUM_DAYS_TO_FETCH, # Integer
    output_file: $stdout, # File-like

    # Default to "warning" level as a nice mix between being quiet and being
    # noisy. If the user wishes to change this, they can choose a different
    # level with any of `--debug`, `--verbose`, or `--quiet`.
    log_level: :warn,

    # Program-specific configuration, mostly required.
    channel_tokens: Set.new, # Set<String>
    country: nil, # :USA | :CAN
    postal_code: nil, # String
    provider_id: nil, # String
                      })

  option_parser = OptionParser.new do |opts|
    opts.program_name = PROGRAM_NAME
    opts.version = "v#{VERSION}" # Pre-pending `v` makes it look nicer
    opts.release = RELEASE

    ############################################################################
    # GENERIC OPTIONS
    ############################################################################

    # Manually specifying these ensures they show up in `--help` output instead
    # of simply being silently available without obvious provenance.

    opts.on(
      '-h',
      '--help',
      'Output program help text and exit.',
    ) do
      config[:return_help_text?] = true
    end

    opts.on(
      '-v',
      '--version',
      'Output program version information and exit.',
    ) do
      config[:return_version_info?] = true
    end

    ############################################################################
    # XMLTV OPTIONS
    ############################################################################

    #
    # Minimum required options
    #

    opts.on(
      '--description',
      'Output our XMLTV description and exit.',
    ) do
      config[:return_description?] = true
    end

    opts.on(
      '--capabilities',
      'Output our supported XMLTV capabilities and exit.',
    ) do
      config[:return_capabilities?] = true
    end

    #
    # `baseline` options
    #

    opts.on(
      '-q',
      '--quiet',
      'Log only at the error level and higher.',
    ) do
      config.log_level = :error
    end

    output_flag = '--output'
    opts.on(
      '-o PATH',
      "#{output_flag} PATH",
      'Write output to this file instead of standard output.',
    ) do |p|
      config.output_file = Arg
        .name(output_flag)
        .path_name
        .stream('w')
        .parse(p)
    end

    days_flag = '--days'
    opts.on(
      '-d DAYS',
      "#{days_flag} DAYS",
      'The number of days of data to obtain, default "as many as are available"',
    ) do |d|
      config.days_to_fetch = Arg
        .name(days_flag)
        .int
        .min(1)
        .max(ZAP2IT_MAXIMUM_DAYS_TO_FETCH)
        .parse(d)
    end

    offset_flag = '--offset'
    opts.on(
      '-f DAYS',
      "#{offset_flag} DAYS",
      'Obtain data starting on the date this many days from today. Default is 0, i.e. "today", 1 is "tomorrow", etc.',
    ) do |o|
      config.day_offset = Arg
        .name(offset_flag)
        .int
        .parse(o)
    end

    config_file_flag = '--config-file'
    opts.on(
      "#{config_file_flag} PATH",
      'The path to the (optional) configuration file for this grabber.',
    ) do |p|
      config_path = Arg
        .name(config_file_flag)
        .path_name
        .exists
        .parse(p)

      # Reads command line options from the given file and parses them.
      #
      # We do this "in line" so that options are applied "logically", i.e.
      # options that come _before_ this flag are overwritten, but options that
      # come _after_ this flag overwrite previously-loaded options.
      opts.load(config_path)
    end

    #
    # `cache` options
    #

    cache_flag = '--cache'
    opts.on(
      "#{cache_flag} PATH",
      'If given, a file in which to cache network requests across invocations.',
    ) do |p|
      cache_filename = Arg
        .name(cache_flag)
        .path_name
        .parse(p)

      config.cache = Cache.new(cache_filename)
    end

    ############################################################################
    # PROGRAM OPTIONS
    ############################################################################

    debug_flag = '--debug'
    opts.on(
      debug_flag,
      'Enable all logging; this is the most verbose level of output available.',
    ) do
      config.log_level = :debug
    end

    verbose_flag = '--verbose'
    opts.on(
      verbose_flag,
      'Enable logging at the info level and higher.',
    ) do
      config.log_level = :info
    end

    country_flag = '--country'
    opts.on(
      '-c COUNTRY',
      "#{country_flag} COUNTRY",
      'The country for which to fetch data, one of USA or CAN.',
    ) do |s|
      config.country = Arg
        .name(country_flag)
        .strip
        .one_of('USA', 'CAN')
        .symbolize
        .parse(s)
    end

    postal_code_flag = '--postal-code'
    opts.on(
      '-p CODE',
      "#{postal_code_flag} CODE",
      'The postal code for which to fetch data. Something like `12345` for the USA or `A1A 1A1` for Canada.`',
    ) do |s|
      config.postal_code = Arg
        .name(postal_code_flag)
        .strip
        .substitute(/\s+/, ' ') # Condense spaces for uniformity
        .non_empty
        .parse(s)
    end

    show_provider_info_flag = '--show-providers'
    opts.on(
      show_provider_info_flag,
      "Output provider information for the given #{country_flag} and #{postal_code_flag} values.",
    ) do |_s|
      config[:return_providers?] = true
    end

    provider_id_flag = '--provider-id'
    opts.on(
      '-r ID',
      "#{provider_id_flag} ID",
      "The provider id for which to fetch data, obtained with the help of the #{show_provider_info_flag} flag.",
    ) do |s|
      config.provider_id = Arg
        .name(provider_id_flag)
        .strip
        .non_empty
        .parse(s)
    end

    show_channels_flag = '--show-channels'
    opts.on(
      show_channels_flag,
      "Output the channels for the given #{country_flag}, #{postal_code_flag}, and #{provider_id_flag} values.",
    ) do
      config[:return_channels?] = true
    end

    channels_flag = '--channels'
    opts.on(
      "#{channels_flag} CHANNELS",
      'A comma-delimited list of channel call signs, numbers, and/or ids for which to download data. If non are provided, all available channels will be downloaded.',
    ) do |s|
      raw_channels = Arg
        .name(channels_flag)
        .strip
        .non_empty
        .parse(s)

      config.channel_tokens = raw_channels
        .split(/,/)
        .map(&:strip) # Handle interior whitespace
        .reject(&:empty?) # Remove empty strings
        .to_set
    end

    show_lineup_flag = '--show-lineup'
    opts.on(
      show_lineup_flag,
      "Output the program lineup(s) for the given #{channels_flag} values.",
    ) do
      config[:return_lineup?] = true
    end
  end

  # It's useful for external things to have access to this at times, e.g. for
  # printing help text.
  config.option_parser = option_parser

  # Parse the given arguments into our config object.
  option_parser.parse(args)

  config
end

# A map of host names to the last time we completed a request to them. We use
# this to enforce a minimum time between HTTP requests to a given host.
LAST_FETCH_END_TIMES_BY_HOST = Hash.new { Time.at(0).getutc }

# A cache for requests that fail a full retry cycle. We use this to effectively
# skip them if they've failed in this manner recently so as not to clog up the
# request pipeline needlessly with likely-failing requests.
FETCH_RETRY_FAILURE_TIMES_BY_CACHE_KEY = Hash.new { Time.at(0).getutc }

# Makes a GET or POST request to some host/path combination and returns the
# string response data. If the request fails, raises an `IOError`.
def fetch(
  *path_parts, # Array<any>
  query: nil, # Hash<Symbol, any> | nil
  data: nil, # Hash<Symbol | String, JSON> | nil
  cache: Cache.new, # Cache
  ttl_seconds: nil, # Integer
  should_retry_posts: false # Boolean, whether POST requests should be retried
) # String
  full_path = File.join(*path_parts.map(&:to_s))

  uri =
    begin
      u = URI.parse(full_path)

      unless query.nil?
        u.query = URI.encode_www_form(query.to_a)
      end

      u
    rescue URI::InvalidURIError => e
      raise ArgumentError, "Invalid URI from path #{full_path.inspect}: #{e}"
    end

  LOG.info do
    parts = ["Fetching URI #{uri}"]
    parts << " with data #{data.inspect}" if data
    parts.join
  end

  cache_key = digest(
    u, # The full request URL
    URI.encode_www_form(data || {}), # POST data for the request, if any
    format: :base64,
    length: 32,
  )

  # If a request has failed a full retry cycle recently, ignore it and
  # immediately raise an appropriate error so we don't clog up the request
  # pipeline with always-failing requests.
  now = Time.now.getutc
  if FETCH_RETRY_FAILURE_TIMES_BY_CACHE_KEY[cache_key] > now - (5 * TimeInterval::MINUTES)
    raise IOError, "Fast-failing HTTP request to URI #{uri} since it failed a full retry cycle recently"
  end

  LOG.debug do
    parts = ["Looking up request to #{uri}"]
    parts << " with data #{URI.encode_www_form(data)}" unless data.nil?
    parts << ' in cache'
    parts.join
  end
  cache.fetch(cache_key, ttl_seconds) do
    # Delay the fetch as necessary to enforce a minimum amount of time between
    # requests to any one host.
    #
    # Note that we do this _within the cache block_ so that any already-cached
    # values aren't unnecessarily delayed.
    last_fetch_end_time_for_host = LAST_FETCH_END_TIMES_BY_HOST[uri.host]
    earliest_next_fetch_start_time = last_fetch_end_time_for_host + FETCH_MIN_SECONDS_BETWEEN_REQUESTS
    if now < earliest_next_fetch_start_time
      wait_seconds = earliest_next_fetch_start_time - now
      LOG.debug("Delaying for #{wait_seconds}s before next request to host #{uri.host}")

      sleep(wait_seconds)
    end

    begin
      method = data.nil? ? :GET : :POST

      LOG.debug("Response not found in cache, making #{method} request to URI #{uri}")

      # Don't allow things to take too long since we might be making a lot of
      # requests.
      res =
        begin
          # This is the first attempt, so we count from 1 instead of 0.
          attempts ||= 1

          response = Net::HTTP.start(
            uri.host,
            uri.port,
            use_ssl: u.scheme == 'https',
            open_timeout: HTTP_REQUEST_TIMEOUT_SECONDS,
            read_timeout: HTTP_REQUEST_TIMEOUT_SECONDS,
            write_timeout: HTTP_REQUEST_TIMEOUT_SECONDS,
            ssl_timeout: HTTP_REQUEST_TIMEOUT_SECONDS,
          ) do |http|
            body_data =
              if data.nil?
                nil
              else
                URI.encode_www_form(data)
              end

            http.send_request(
              method,
              uri.request_uri,
              body_data,
              # As a good netizen, we identify ourself unambiguously.
              { 'User-Agent' => VERSION_INFO },
            )
          end

          # According to the docs, simply calling this method should raise a
          # HTTP error if the result wasn't a success.
          response.value

          response
        rescue \
            Net::HTTPBadResponse,
            Net::HTTPFatalError,
            Net::HTTPServerError,
            Net::HTTPTooManyRequests,
            Net::OpenTimeout,
            Net::ReadTimeout,
            Net::WriteTimeout,
            SocketError,
            OpenSSL::SSL::SSLError \
            => e
          # If we've failed too many times or aren't supposed to retry, give up.
          if attempts > 5 || (method == :POST && !should_retry_posts)
            LOG.debug do
              if method == :POST && !should_retry_posts
                "Declining to retry POST request to URI #{uri}"
              else
                "Failed to make HTTP #{method} request to URI #{uri} after #{attempts} attempts"
              end
            end

            # Mark this request as having failed a full retry cycle recently so
            # we can skip it if it comes up again in the near future.
            FETCH_RETRY_FAILURE_TIMES_BY_CACHE_KEY[cache_key] = Time.now.getutc

            # Convert to `IOError` so we can easily handle this in the caller if
            # desired.
            raise IOError, "Failed to make HTTP #{method} request to URI #{uri}: #{e}"
          end

          LOG.warn("Got non-successful HTTP response (#{e}); retrying (attempts so far: #{attempts})")

          backoff_seconds = 2**attempts
          LOG.debug("Backing off for #{backoff_seconds}s before retrying HTTP #{method} request to URI #{uri}")
          sleep(backoff_seconds)

          attempts += 1
          retry
        end

      # Return the body data.
      res.body
    ensure
      # We mark the _true_ end of the fetch so we can conservatively enforce our
      # rate limit between _response times_ rather than between _request times_.
      #
      # This is useful since any given response might take several seconds to
      # come in, and we don't want to allow making another separate request
      # immediately, possibly overloading the remote server, just because the
      # prior one took a long time.
      #
      # Note that we also do this for failed responses, which ensures that even
      # if failures are happening we're being nice to the API.
      last_host_fetch_time = Time.now.getutc
      LOG.debug("Setting last fetch time for host #{uri.host} to #{last_host_fetch_time}")
      LAST_FETCH_END_TIMES_BY_HOST[uri.host] = last_host_fetch_time
    end
  end
end

# Makes a GET or POST request to some host/path combination and returns the JSON
# response with symbolized keys. If the request fails or its response body can't
# be parsed, raises an `IOError`.
def fetch_json(
  *path_parts, # Array<any>
  query: nil, # Hash<Symbol, any> | nil
  data: nil, # Hash<Symbol | String, JSON> | nil
  cache: Cache.new, # Cache
  ttl_seconds: nil, # Integer
  should_retry_posts: false # Boolean, whether POST requests should be retried
) # JSON
  # Parse the body as JSON, the only response format we expect to receive.
  body = fetch(
    *path_parts,
    query: query,
    data: data,
    cache: cache,
    ttl_seconds: ttl_seconds,
    should_retry_posts: should_retry_posts,
  )

  begin
    LOG.debug('Attempting to parse response body as JSON')
    JSON.parse(body, symbolize_names: true)
  rescue JSON::ParserError => e
    LOG.warn('Failed initial parse of response body, retrying with corrected body')

    # Guess what? Sometimes, the API returns improperly-escaped JSON
    # strings!
    #
    # These seem to take the form of faulty attempts to escape quotes within
    # strings, where the backslash is escaped instead of the quote itself.
    #
    # E.g. we've seen things like:
    #
    # ```json
    # {
    #    "prop": "Foo \\"bar\\" baz!"
    # }
    # ```
    #
    # These should _probably_ be:
    #
    # ```json
    # {
    #    "prop": "Foo \"bar\" baz!"
    # }
    # ```
    #
    # If the parse fails, we make a last-ditch attempt to "rescue" it by
    # replacing such known instances of bad escaping, before finally giving
    # up if we're unable to do so.
    begin
      corrected_body = body.gsub(/\\\\"/, '\\"')
      JSON.parse(corrected_body, symbolize_names: true)
    rescue JSON::ParserError => err
      raise IOError, "Failed to parse HTTP response from #{method} request to URI #{uri}: #{err}"
    end
  end
end

# Scans the given HTML for non-nested (i.e. "leaf") tags of the given type, then
# yields each `MatchObject` in turn. Returns the list of matched tags in the
# order they matched.
def scan_unnested_html_tag(
  html, # String
  tag # String, e.g. `table`, `div`, `span`, etc.
) # Iterable<MatchObject>
  escaped_tag = Regexp.escape(tag)

  html
    .scan(%r{<#{escaped_tag}(?:(?!(?:<#{escaped_tag}|</#{escaped_tag}>)).)*</#{escaped_tag}>}m)
    .map do |match|
      yield match if block_given?
      match
    end
end

# Removes all HTML tags from the input, but leaves their content. This strips
# only the tag _syntax_, not the tag _content_!
def strip_html_tags(
  html # String
) # String
  html.gsub(/<[^>]+>/, '')
end

def unescape_html(
  html # String
) # String
  CGI
    .unescapeHTML(html)
    .gsub(/&nbsp;/i, ' ')
end

# Retrive the rabbitears.info page information for a TV station and obtain the
# affiliate information from said page. If no affiliate information can be found
# for the given call sign prefix, returns `nil`.
def fetch_station_affiliate_info(
  country, # :USA | :CAN
  call_sign, # String, something like `KABCDT1`
  cache: Cache.new # Cache
) # Hash<String channel number, String affiliate name> | nil
  LOG.info("Fetching station affiliations for channel call sign #{call_sign} and country #{country}")

  # Attempt to use `rabbitears.info` to retrieve station channel number to
  # human-readable name mappings.
  market_html = fetch(
    RABBITEARS_HOST,
    '/market.php',
    query: {
      request: :station_search,

      # Only use the first 4 characters since that's the "real" callsign
      # according to the FCC.
      callsign: call_sign[0...4],
    },

    # This response is expected to change very infrequently, if ever.
    cache: cache,
    ttl_seconds: 30 * TimeInterval::DAYS,
  )

  # Let's parse HTML using regular expressions! Luckily for us, this is _very_
  # simple HTML and we don't need to parse _all_ HTML, only _RabbitEars_' HTML.
  #
  # Ultimately, the response contains a table like the following (beautified
  # for ease of reading):
  #
  # ```html
  # <table class="stationchannels" width="100%">
  #  <thead>
  #      <tr>
  #          <td width="0%" colspan="2"><acronym title="How the subchannel displays on receivers">Display<br>Channel</acronym></td>
  #          <td width="0%" colspan="2"><acronym title="Before the dot, the physical channel number; after the dot, the MPEG-2 Program Number">Physical<br>Channel</acronym></td>
  #          <td width="0%" colspan="2"><acronym title="Resolution of the video stream of this subchannel">Video</acronym></td>
  #          <td width="0%"><acronym title="Highest quality audio stream available on this subchannel">Audio</acronym></td>
  #          <td width="0%"><acronym title="Seven character ID sent by the station to identify the subchannel on receivers">Call&nbsp;Sign</acronym>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
  #          <td width="0%" colspan="2"><acronym title="Network affiliation or type of programming">Network/Programming</acronym>&nbsp;&nbsp;&nbsp;</td>
  #          <td width="65%"><acronym title="What the subchannel is called on-air">Nickname</acronym></td>
  #          <td width="70%"><acronym title="A call sign indicates this subchannel repeats programming from the noted station; a date indicates this subchannel will launch on that date">Notes</acronym></td>
  #          <td style="text-align:right;" width="0%">&nbsp;<a href="/market.php?request=print_station&amp;facility_id=8564" target="_new">Print</a>
  #          </td>
  #      </tr>
  #  </thead>
  #
  #  <tbody>
  #      <tr valign="middle">
  #          <td>
  #              <nobr><a href="http://www.klru.org/" target="_new">18-1 <img border="0" src="/img/external.png" alt=""></a><img src="/img/gosulspacer.png" height="16" width="1" alt=""></nobr>
  #          </td>
  #          <td><img src="/img/gosulspacer.png" height="16" width="1" alt=""></td>
  #          <td>22.3</td>
  #          <td>
  #              <nobr><img src="/img/gosulspacer.png" height="16" width="1" alt=""></nobr>
  #          </td>
  #          <td>1080i<img src="/img/gosulspacer.png" height="16" width="1" alt=""></td>
  #          <td></td>
  #          <td>DD5.1&nbsp;<img title="This subchannel transmits secondary audio." src="/img/sap.png" border="0" width="16" height="16" alt="SAP Audio Icon"></td>
  #          <td>
  #              <nobr>KLRU-HD<img src="/img/gosulspacer.png" height="16" width="1" alt=""></nobr>
  #          </td>
  #          <td colspan="2">
  #              <nobr><a href="/search.php?request=network_search&amp;network=PBS">PBS</a>&nbsp;
  #                  <a href="http://www.pbs.org/" target="_new"><img border="0" src="/img/external.png" alt=""></a>
  #              </nobr><img src="/img/gosulspacer.png" height="16" width="1" alt=""></td>
  #          <td colspan="3">"Austin PBS"&nbsp;<img src="/img/gosulspacer.png" height="16" width="1" alt=""></td>
  #      </tr>
  #      <tr valign="middle">
  #          <td>
  #              <nobr>18-2<img src="/img/gosulspacer.png" height="16" width="1" alt=""></nobr>
  #          </td>
  #          <td><img src="/img/gosulspacer.png" height="16" width="1" alt=""></td>
  #          <td>22.4</td>
  #          <td>
  #              <nobr><img src="/img/gosulspacer.png" height="16" width="1" alt=""></nobr>
  #          </td>
  #          <td>480i&nbsp;(<acronym title="Widescreen SD">w</acronym>)<img src="/img/gosulspacer.png" height="16" width="1" alt=""></td>
  #          <td></td>
  #          <td>DD2.0&nbsp;<img title="This subchannel transmits secondary audio." src="/img/sap.png" border="0" width="16" height="16" alt="SAP Audio Icon"></td>
  #          <td>
  #              <nobr>KLRU-CR<img src="/img/gosulspacer.png" height="16" width="1" alt=""></nobr>
  #          </td>
  #          <td colspan="2">
  #              <nobr><a href="/search.php?request=network_search&amp;network=Create">Create</a>&nbsp;
  #                  <a href="http://www.createtv.com/" target="_new"><img border="0" src="/img/external.png" alt=""></a>
  #              </nobr><img src="/img/gosulspacer.png" height="16" width="1" alt=""></td>
  #          <td colspan="3">&nbsp;<img src="/img/gosulspacer.png" height="16" width="1" alt=""></td>
  #      </tr>
  #      <tr valign="middle">
  #          <td>
  #              <nobr>18-3<img src="/img/gosulspacer.png" height="16" width="1" alt=""></nobr>
  #          </td>
  #          <td><img src="/img/gosulspacer.png" height="16" width="1" alt=""></td>
  #          <td>22.5</td>
  #          <td>
  #              <nobr><img src="/img/gosulspacer.png" height="16" width="1" alt=""></nobr>
  #          </td>
  #          <td>480i&nbsp;(<acronym title="Widescreen SD">w</acronym>)<img src="/img/gosulspacer.png" height="16" width="1" alt=""></td>
  #          <td></td>
  #          <td>DD2.0&nbsp;<img title="This subchannel transmits secondary audio." src="/img/sap.png" border="0" width="16" height="16" alt="SAP Audio Icon"></td>
  #          <td>
  #              <nobr>KLRU-WO<img src="/img/gosulspacer.png" height="16" width="1" alt=""></nobr>
  #          </td>
  #          <td colspan="2">
  #              <nobr><a href="/search.php?request=network_search&amp;network=PBS+Encore">PBS Encore</a>&nbsp;
  #                  <a href="http://www.pbs.org/" target="_new"><img border="0" src="/img/external.png" alt=""></a>
  #              </nobr><img src="/img/gosulspacer.png" height="16" width="1" alt=""></td>
  #          <td colspan="3">&nbsp;<img src="/img/gosulspacer.png" height="16" width="1" alt=""></td>
  #      </tr>
  #      <tr valign="middle">
  #          <td>
  #              <nobr>18-4<img src="/img/gosulspacer.png" height="16" width="1" alt=""></nobr>
  #          </td>
  #          <td><img src="/img/gosulspacer.png" height="16" width="1" alt=""></td>
  #          <td>22.6</td>
  #          <td>
  #              <nobr><img src="/img/gosulspacer.png" height="16" width="1" alt=""></nobr>
  #          </td>
  #          <td>480i&nbsp;(<acronym title="Widescreen SD">w</acronym>)<img src="/img/gosulspacer.png" height="16" width="1" alt=""></td>
  #          <td></td>
  #          <td>DD2.0&nbsp;<img title="This subchannel transmits secondary audio." src="/img/sap.png" border="0" width="16" height="16" alt="SAP Audio Icon"></td>
  #          <td>
  #              <nobr>PBSKids<img src="/img/gosulspacer.png" height="16" width="1" alt=""></nobr>
  #          </td>
  #          <td colspan="2">
  #              <nobr><a href="/search.php?request=network_search&amp;network=PBS+Kids+24%2F7">PBS Kids 24/7</a>&nbsp;
  #                  <a href="http://pbskids.org/" target="_new"><img border="0" src="/img/external.png" alt=""></a>
  #              </nobr><img src="/img/gosulspacer.png" height="16" width="1" alt=""></td>
  #          <td colspan="3">&nbsp;<img src="/img/gosulspacer.png" height="16" width="1" alt=""></td>
  #      </tr>
  #    </tbody>
  #  </table>
  # ```
  #
  # Our steps:
  # 1. Extract all tables (assuming no nested tables)
  # 2. Keep only the "stationchannels" table
  # 3. Extract the `<tbody>`
  # 4. Split into individual `<tr>` rows
  # 5. Split into individual `<td>` columns
  # 6. Strip _all_ tags from the column text content
  # 7. Use first column as channel number, replacing `-` in "18-1" with `.`
  # 8. In order of existence:
  #   a. Use seventh column "nickname" name
  #   b. Use sixth column "network" name
  #   c. Use fifth column "call sign" name

  # Find our station's special "table row", which contains the ID of the station
  # that matched the search.
  station = scan_unnested_html_tag(market_html, 'tr')
    .find { |t| /id=["']?station["']/ =~ t }
  if station.nil?
    LOG.debug('Could not find matching TV station in response, giving up')
    return nil
  end

  # The station element contains a call like `toggleStation('_12_3456')` that
  # specifies the ID of the station that matched the searched call sign. We
  # extract the ID.
  station_id_match = /toggleStation\(['"`](.+?)['"`]\)/.match(station)
  station_id = station_id_match[1]
  if station_id.nil?
    LOG.debug('Could not extract station ID from matching station, giving up')
    return nil
  end

  # Find the next table _after_ the station ID match; this is the table
  # containing all the child channels.
  table_match = scan_unnested_html_tag(
    market_html
      .split(station_id_match.to_s, 2)
      .last,
    'table',
  ).first
  if table_match.nil?
    LOG.debug('Could not find station table using matched station ID, giving up')
    return nil
  end

  # Find each non-header row in the table; each of these is a child station.
  channel_infos = scan_unnested_html_tag(table_match.to_s, 'tr')
    .drop(1)
    .flat_map do |row|
      channel_info = {
        channel: nil,
        network: nil,
        nickname: nil,
      }

      scan_unnested_html_tag(row.to_s, 'td')
        .each_with_index do |column, index|
          text = unescape_html(strip_html_tags(column)).strip

          next if text.empty?

          if index == 0
            channel_info[:channel] = text.gsub('-', '.').gsub(/^0+/, '')
          elsif index == 8
            channel_info[:network] = text
          elsif index == 9
            channel_info[:nickname] = text.gsub(/^"|"$/, '')
          end
        end

      channel_info
    end

  channel_infos
    .map { |info| [info[:channel], info[:nickname] || info[:network]] }
    .to_h
end

# Downloads and returns lineup (i.e. provider) data for the given country and
# postal code.
def fetch_providers(
  country, # :USA | :CAN
  postal_code, # String, e.g. `12345` or `A1A 1A1`
  cache: Cache.new # Cache
) # Array<Provider>
  LOG.info("Fetching providers for country #{country} and postal code #{postal_code}")

  provider_json = fetch_json(
    ZAP2IT_API_HOST,
    '/gapzap_webapi/api/Providers/getPostalCodeProviders',
    country,
    postal_code,
    '/gapzap/en',
    # This response is expected to change very infrequently, if ever.
    cache: cache,
    ttl_seconds: TimeInterval::WEEKS,
  )

  provider_json
    .fetch(:Providers)
    .sort_by { |p| [p.fetch(:type), p.fetch(:name)] } # A human-friendly sort for display
    .map do |p|
      Provider.new(
        country: country,
        id: p.fetch(:headendId),
        name: p.fetch(:name),
        postal_code: postal_code,
        type: p.fetch(:type),
      )
    end
end

# Fetch overall provider info and return the provider that corresponds to the
# given parameters. If no provider is found, returns `nil`.
def fetch_provider(
  country, # :USA | :CAN
  postal_code, # String
  provider_id, # String
  cache: Cache.new # Cache
) # Provider | nil
  LOG.info("Fetching single provider id #{provider_id} for country #{country} and postal code #{postal_code}")

  providers = fetch_providers(
    country,
    postal_code,
    cache: cache,
  )

  providers.find do |provider|
    (
      provider.country == country &&
      provider.postal_code == postal_code &&
      provider.id == provider_id
    )
  end
end

# Downloads and returns the channels available for the given provider at the
# given time/time span, potentially limiting them to some list of channels.
def fetch_channels(
  provider, # Provider
  date = Time.now.getutc, # Time, but will be truncated to its date component
  time_span_hours = 6, # 1 | 2 | 3 | 4 | 5 | 6
  channel_tokens: Set.new, # Enumerable<String>. If non-empty, channels to fetch
  cache: Cache.new # Cache
) # Array<Channel>
  LOG.info do
    channels_string =
      if channel_tokens.empty?
        'all channels'
      else
        "channels for tokens #{channel_tokens.to_a.sort.join(', ')}"
      end

    "Fetching #{channels_string} from provider #{provider} (time span: #{time_span_hours}h, date: #{date})"
  end

  # We need fast random access to these.
  channel_tokens = channel_tokens.to_set

  # When fetching channels, we really only care about "right now" and don't
  # expect the values to change much over time. However, we cache the response
  # for a while anyway.
  ttl_seconds = 1 * TimeInterval::DAYS

  lineup_json = fetch_json(
    ZAP2IT_API_HOST,
    '/api/grid',
    query: {
      # Unused since we give `headendId`, but apparently necessary anyway!
      lineupId: '-',

      # Provider info
      headendId: provider.id,
      country: provider.country,
      postalCode: provider.postal_code,

      # Time info, truncated to "today" for caching purposes.
      timespan: time_span_hours,
      time: truncate_time(date, ttl_seconds).to_i, # Needs to be Unix time, apparently
    },

    cache: cache,
    ttl_seconds: ttl_seconds,
  )

  # We sort by channel number for a human-friendly display and limit our
  # channels to the ones requested.
  raw_channels = lineup_json
    .fetch(:channels)
    .sort_by do |c|
      [
        begin
          Float(c.fetch(:channelNo))
        rescue
          c.fetch(:channelNo)
        end,
        c.fetch(:callSign),
      ]
    end
    .select do |c|
      (
        # If we weren't given any channels to which to limit our fetch, keep all
        # channels.
        channel_tokens.empty? ||

        # Otherwise, keep only channels that have an identifier that matches one
        # of the given tokens.
        channel_tokens.include?(c.fetch(:channelId)) ||
        channel_tokens.include?(c.fetch(:callSign)) ||
        channel_tokens.include?(c.fetch(:channelNo))
      )
    end

  # If we got no channels after filtering things down, clearly tell the user
  # what happened.
  if raw_channels.empty?
    channel_tokens_string = channel_tokens
      .to_a
      .sort
      .join(', ')
    raise ArgumentError, "Could not find any channels matching these tokens: #{channel_tokens_string}"
  end

  raw_channels.map do |c|
    affiliates = fetch_station_affiliate_info(
      provider.country,
      c.fetch(:callSign),
      cache: cache,
    ) || {}

    channel_name = affiliates[c.fetch(:channelNo)]

    Channel.new(
      provider: provider,
      call_sign: c.fetch(:callSign),
      name: channel_name,
      id: c.fetch(:channelId),
      number: c.fetch(:channelNo),
      image_url: c.fetch(:thumbnail),
    )
  end
end

# Fetch overall channel info and return the channel that corresponds to the
# given token. If no channel is found, returns `nil`.
def fetch_channel(
  provider, # Provider
  token, # String, one of a channel call sign, number, or id
  date = Time.now.getutc, # Time, but will be truncated to its date component
  time_span_hours = 6, # 1 | 2 | 3 | 4 | 5 | 6
  cache: Cache.new # Cache
) # Channel | nil
  LOG.info do
    "Fetching single channel for token #{token} from provider #{provider} (time span: #{time_span_hours}h, date: #{date})"
  end

  channels = fetch_channels(
    provider,
    date,
    time_span_hours,
    cache: cache,
  )

  channels.find do |channel|
    (
      channel.call_sign == token ||
      channel.id == token ||
      channel.number == token
    )
  end
end

def get_lineup_date_cache_key(
  channel, # Channel
  start_time # Time, but will be truncated to its date
) # String
  digest(
    # These are the same values as required by the actual API request, so we use
    # them for symmetry.
    channel.id,
    channel.provider.country,
    channel.provider.postal_code,
    channel.provider.id,
    # The date string for which we want to find guide data.
    #
    # We use our own to ensure that the cached date is always consistent,
    # regardless of what/how the zap2it API decides to return the date keys for
    # the lineup. Mainly, this is guarding against zap2it returning something
    # like `2020-1-1` instead of `2020-01-01`.
    truncate_time(start_time, TimeInterval::DAYS).strftime('%Y-%m-%d'),
  )
end

# Returns `true` when the given series id looks like that of a movie.
def is_movie_id(
  series_id # String
) # Boolean
  # Movies have series ids that start with `MV`!
  /^MV/i.match?(series_id)
end

# Attempts to fetch and return detailed program information for the given
# program/series combination. This works for both movies _and_ televsion shows!
def fetch_program_details(
  series_id, # String, the `seriesId` value fetched from lineup program info
  program_id, # String, the `tmsId` fetched from lineup program info
  season_index: nil, # Integer, one-based, the season to fetch. `nil` means "latest season", 1 means "first season", etc.
  cache: Cache.new # Cache
) # JSON program details
  Arg
    .name('series_id')
    .is_a(String)
    .non_empty
    .parse(series_id)
  Arg
    .name('program_id')
    .is_a(String)
    .non_empty
    .parse(program_id)
  unless season_index.nil?
    Arg
      .name('season_index')
      .is_a(Integer)
      .min(1)
      .parse(season_index)
  end

  LOG.info("Fetching detailed program information for series id #{series_id}, program id #{program_id} (season index: #{season_index.inspect})")

  # The API only allows us to look up detailed information for a whole season at
  # a time. Since we often don't even know which season a particular episode
  # came from since the initial API call returns null, we instead always start
  # by fetching the latest season, then walking the season list backwards until
  # we find the episode we're looking for.
  #
  # We fetch from latest to earliest under the assumption that most often newer
  # episodes are aired in preference to older ones.

  # When fetching the latest season, we don't cache the result for very long.
  # This ensures that unfinished seasons are re-checked regularly, but "old"
  # seasons and movies are cached for a good long time since presumably they
  # won't change very often at all!
  ttl_seconds =
    if is_movie_id(series_id) || !season_index.nil?
      90 * TimeInterval::DAYS
    else
      TimeInterval::DAYS
    end

  season_info =
    begin
      fetch_json(
        ZAP2IT_API_HOST,
        '/gapzap_webapi/api/program/PostEpisodeGuide',
        data: {
          # A magical required value!
          aid: :gapzap,

          # Essentially, "fetch all the data in a single page". This seems to work
          # without issue in all attempted cases, so... we don't have to paginate!
          pageNo: 1,
          pageSize: 999,

          # Fetch the series/season we care about right now.
          programSeriesID: series_id,
          season: season_index || -1, # Convert `nil` to `-1` for "latest season"
        },

        should_retry_posts: true,
        cache: cache,
        ttl_seconds: ttl_seconds,
      )
    rescue IOError => e
      # If one of these requests perma-fails, return `nil` and pretend we simply
      # couldn't find the info. Since this info is nice-to-have, we can proceed
      # without it.
      LOG.warn("Detailed info request for series id #{series_id}, program id #{program_id}, season index #{season_index.inspect} failed: '#{e}'; returning nothing instead of exploding")
      return nil
    end

  episodes_info = season_info
    .fetch(:episodeGuideTab)
    .fetch(:season)
    .fetch(:episodes)

  # See if this response contained the episode information we're looking for.
  #
  # The `tmsId` value we get in `program_id` is prefixed with `SH` or `sh`
  # coming from the program guide, but is listed as `ep` in the season
  # details...
  #
  # We munge during the comparison with the program details episode id to
  # account for this and any general variation on it.
  id_munge_prefix_regex = /^(SH|EP)/i
  munged_query_episode_id = program_id.gsub(id_munge_prefix_regex, '')
  episode_details = episodes_info.find do |episode_info|
    munged_candidate_episode_id = episode_info.fetch(:tmsID).gsub(id_munge_prefix_regex, '')
    munged_candidate_episode_id == munged_query_episode_id
  end

  # If we didn't find what we were looking for in this season, iterate backwards
  # to the next season until we either find our episode or run out of seasons.
  if episode_details.nil?
    potential_season_indices = season_info
      .fetch(:episodeGuideTab)
      .fetch(:seasons)
      .map { |s| s.to_i(10) } # We expect all seasons to be string integers
      .sort
      .reverse

    # Turn `nil` into the latest season id.
    current_season_index =
      if season_index.nil?
        # Use the largest season index, i.e. the latest season, if we used the
        # "shortcut" of `nil` to fetch the season.
        potential_season_indices.max
      else
        # Otherwise, use the value we were given.
        season_index
      end

    previous_season_index = current_season_index - 1
    return (
      # Season 0 appears to be a nonsense season and doesn't actually count for
      # anything. It looks like it contains a bunch of dummy episodes most of
      # the time, none of which appears to contain useful information anyway!
      if !potential_season_indices.include?(previous_season_index) || previous_season_index.zero?
        # If we get to the point where we want to search through the episodes of
        # the prior season, but there isn't a season that fits the bill, we're
        # out of seasons and aren't going to find the episode details we want.
        nil
      else
        # Recursively fetch and look through the prior season's details.
        fetch_program_details(
          series_id,
          program_id,
          season_index: previous_season_index,
          cache: cache,
        )
      end
    )
  end

  # Since we found the desired episode details, we can now fetch the general
  # overview information for the series, which contains things like writers,
  # directory, actors, etc. that we can use for program credits.
  overview_info =
    begin
      fetch_json(
        ZAP2IT_API_HOST,
        '/api/program/overviewDetails',
        data: {
          programSeriesID: series_id,
        },

        should_retry_posts: true,
        cache: cache,
        ttl_seconds: (
          if is_movie_id(series_id)
            # Movies are considered "done", so we can cache their information for a
            # long time.
            30 * TimeInterval::DAYS
          else
            # Cache TV series overview information for a shorter time than that for
            # movies since many series are ongoing and may have changing cast and
            # crew credits.
            7 * TimeInterval::DAYS
          end
        ),
      )
    rescue IOError => e
      LOG.warn("Overview info request for series id #{series_id} failed with error '#{e}'; proceeding without it")

      # If we can't fetch this data, ignore it since it's not critical that we
      # get it.
      nil
    end

  # Since we found our desired episode details, we can now parse them!

  # Can be the empty string when a rating is (presumably) unknown.
  display_rating = episode_details.fetch(:displayRating)
  rating =
    if display_rating.nil? || display_rating.empty?
      nil
    else
      display_rating
    end

  # Movies have their release year populated with a string year like `1976` but
  # an original air date of `1000-01-01`, whereas TV show episodes have an
  # accurate original air date but an empty string release year. We'll also
  # occasionally get neither!
  raw_release_year = episode_details.fetch(:releaseYear, '')
  raw_original_air_date = episode_details.fetch(:originalAirDate, '')
  original_release_date =
    if !raw_release_year.empty?
      # We use the first of the year as a dummy day since having a release year
      # almost certainly means we're dealing with a movie for which we _only_
      # have a year anyway.
      Date.parse("#{raw_release_year}-01-01").to_time.getutc
    elsif !raw_original_air_date.empty?
      Date.parse(raw_original_air_date).to_time.getutc
    else
      # This is the typical "dummy date" we see in the API responses, so we use
      # it for parity.
      Date.parse('1000-01-01').to_time.getutc
    end

  # If one or both of the potential dates was nonsense, we set the value to
  # `nil` to clearly indicate as much.
  original_release_date = nil if original_release_date.year < 1500

  title = episode_details.fetch(:episodeTitle).strip
  title = nil if title.empty?

  description = episode_details.fetch(:synopsis).strip
  description = nil if description.empty?

  # A season of zero appears to indicate some sort of dummy, placeholder season
  # most (all?) of the time and hence should act as if it's not present at all.
  # If present, these are 1-based, though "special" episodes (e.g. clip shows or
  # series retrospectives) might get an episode number of `0`.
  season = episode_details.fetch(:seasonNumber, '-1').to_i(10)
  season = nil if season <= 0

  episode = episode_details.fetch(:episodeNumber, '-1').to_i(10)
  episode = nil if episode < 0

  tags = episode_details
    .fetch(:tags)
    .split('|')
    .map(&:strip)
    .reject(&:empty?)

  genres = episode_details
    .fetch(:programGenres)
    .split('|')
    .map(&:strip)
    .reject(&:empty?)

  is_new = episode_details.fetch(:isNew)
  is_live = episode_details.fetch(:isLive)
  is_premiere = episode_details.fetch(:isPremier)
  is_finale = episode_details.fetch(:isFinale)

  # The credits seem to always come to us in priority order, so we simply keep
  # them in the order in which they were received.
  credits = []
  unless overview_info.nil?
    cast_and_crew = [
      *overview_info.fetch(:overviewTab).fetch(:cast),
      *overview_info.fetch(:overviewTab).fetch(:crew),
    ]
    credits = cast_and_crew.map do |person|
      role = person.fetch(:role)
      name = person.fetch(:name)
      character_name =
        if (raw_character_name = person.fetch(:characterName).strip).empty?
          nil
        else
          raw_character_name
        end

      # Attempt to map the "role" value we were given to a supported kind of
      # XMLTV credit.
      type =
        if /director/i.match?(role)
          :director
        elsif /guest/i.match?(role)
          :guest
        elsif /actor/i.match?(role)
          :actor
        elsif /narrator/i.match?(role)
          # Narrators are just special actors to us!
          role = 'Narrator'
          :actor
        elsif /writer/i.match?(role)
          :writer
        elsif /adapter/i.match?(role)
          :adapter
        elsif /producer/i.match?(role)
          :producer
        elsif /composer/i.match?(role)
          :composer
        elsif /editor/i.match?(role)
          :editor
        elsif /presenter|host/i.match?(role)
          :presenter
        elsif /commentator/i.match?(role)
          :commentator
        elsif /voice/i.match?(role)
          :actor
        else
          # If we can't map the kind of credit this person should receive, call
          # them an "actor" since it's better than nothing at all.
          fallback = :actor
          LOG.warn("Couldn't parse credit type for role #{role.inspect}, falling back to #{fallback.inspect}")
          fallback
        end

      {
        type: type,
        name: name,
        role: character_name,
      }
    end.compact
  end

  {
    # We use the id we were given since it may differ from the munged one the
    # episode info contains; we'll treat the input id as the canonical one.
    program_id: program_id,
    season: season,
    episode: episode,
    title: title,
    description: description,
    original_release_date: original_release_date,
    rating: rating,
    tags: tags,
    genres: genres,
    new?: is_new,
    live?: is_live,
    premiere?: is_premiere,
    finale?: is_finale,
    credits: credits,
  }
end

# Downloads and returns all the program data for the given date, if possible.
def fetch_lineup(
  channel, # Channel
  start_date = Time.now.getutc, # Time, but will be truncated to its date component
  end_date = start_date, # Time, but will be truncated to its date component
  cache: Cache.new # Cache
)
  LOG.info("Fetching program lineup channel #{channel} (start date: #{start_date}, end date: #{end_date})")

  start_date = truncate_time(start_date, TimeInterval::DAYS)
  end_date = truncate_time(end_date, TimeInterval::DAYS)

  # We allow these to be equal since our time span is inclusive.
  if end_date < start_date
    raise ArgumentError, "end_date (#{end_date}) must be greater than or equal to start_date (#{start_date})"
  end

  # Our start and end dates must fall within the period starting today and
  # ending 14 days from now. This range is unfortunately all the zap2it API will
  # allow us to retrieve.
  #
  # Technically the API will allow you to request yesterday's data through 14
  # days from _then_, however supporting this technically-15-day-period is more
  # trouble than it's worth as we'd need to make two highly-overlapping requests
  # to retrieve the ends of the ranges.
  now = Time.now.getutc
  min_start_time = truncate_time(now, TimeInterval::DAYS)
  max_end_time = truncate_time(now, TimeInterval::DAYS) + (ZAP2IT_MAXIMUM_DAYS_TO_FETCH * TimeInterval::DAYS)
  if start_date.to_i < min_start_time.to_i
    raise ArgumentError, "Start date of #{start_date} is too early, cannot be earlier than #{min_start_time}"
  elsif end_date.to_i > max_end_time.to_i
    raise ArgumentError, "End date of #{end_date} is too late, cannot be later than #{max_end_time}"
  end

  # Enumerate all the dates between the start and end dates (inclusive) so we
  # know whether we have to fetch new data or not.
  dates_to_fetch = []
  cur_date = start_date
  while cur_date <= end_date
    dates_to_fetch << truncate_time(cur_date, TimeInterval::DAYS)
    cur_date = cur_date + TimeInterval::DAYS
  end

  # First, we check the cache for any existing data for the given dates. This is
  # necessary since every request to the API contains 14 days of data, however
  # it gets cached by `fetch` as one giant blob.
  #
  # If/when we do a _real_ fetch for all this data, we cache it individually by
  # date so we can look up only the required date when necessary and save a
  # bunch of effort around effectively only being able to fetch data for "today
  # + 14 days" from zap2it and not being able to specify an arbitrary single
  # date.
  cached_lineup_data = dates_to_fetch.each_with_object({}) do |date, all|
    cache_key = get_lineup_date_cache_key(channel, date)
    all[date] = cache.get(cache_key)
  end

  # If any of the dates for which we want lineup data wasn't cached, we have to
  # fetch new data.
  need_to_fetch_from_api = cached_lineup_data.values.any?(&:nil?)

  # If there were any dates we couldn't find already-cached data for, we need to
  # attempt to fetch them from the API.
  if need_to_fetch_from_api
    # We cache for only a single day since program lineup info might change for
    # whatever reason, especially further in the future where there's less
    # certainty.
    ttl_seconds = TimeInterval::DAYS

    lineup_data_for_fortnight = fetch_json(
      ZAP2IT_API_HOST,
      '/api/sslgrid',
      data: {
        # A magical required value!
        aid: :gapzap,

        # Channel/provider info
        prgsvcid: channel.id,
        countryCode: channel.provider.country,
        postalCode: channel.provider.postal_code,
        headendId: channel.provider.id,

        # The number of hours of program lineup data to fetch.
        #
        # Only seems to support extremely specific values in certain contexts,
        # `336` (i.e. 14 days) being the most (only?) reliable value.
        timespan: ZAP2IT_MAXIMUM_DAYS_TO_FETCH * TimeInterval::DAYS / TimeInterval::HOURS,

        # To simplify reasoning about what date(s) to return etc., we truncate
        # the current date to midnight UTC and fetch data starting then.
        timestamp: truncate_time(now, TimeInterval::DAYS).to_i,
      },

      should_retry_posts: true,
      cache: cache,
      ttl_seconds: ttl_seconds,
    )

    # Sometimes, the lineup data for a given date simply doesn't exist at all in
    # the response. To prevent having to treat these "missing dates" as special
    # cases later when looking up the data for the date, we stub out all
    # response dates as having empty lineups, _then_ overwrite them with the
    # _real_ response data to add anything we actually received.
    dates_to_fetch.each do |date_to_fetch|
      cache_key = get_lineup_date_cache_key(channel, date_to_fetch)
      cache.set(cache_key, [], ttl_seconds, now: now)
    end

    # The lineup data comes in mapped date string (e.g. `2020-01-02`) to array
    # of programs; we convert this into a cache entry per date.
    lineup_data_for_fortnight.each_pair do |date_sym, lineup_programs|
      # Update the cache with the information for this date alone, allowing it
      # to be accessed separately from the other dated lineups from the API
      # request from which it was fetched.
      lineup_date = Date.parse(date_sym.to_s).to_time.getutc
      cache_key = get_lineup_date_cache_key(channel, lineup_date)
      cache.set(cache_key, lineup_programs, ttl_seconds, now: now)
    end

    # Now that we've (hopefully...) cached the lineup for all of our original
    # dates, we can re-fetch the data directly from the cache.
    cached_lineup_data = cached_lineup_data.each_with_object({}) do |(date, lineup_data), all|
      # Re-fetch the data from the cache if we didn't originally find it there;
      # now that we've intentionally downloaded it from the API, it should
      # certainly exist in the cache!
      if lineup_data.nil?
        lineup_data = cache.get(get_lineup_date_cache_key(channel, date))
      end

      if lineup_data.nil?
        raise IOError, 
"Unexpectedly failed to look up fetched lineup data in cache for date #{date} and channel #{channel}"
      end

      all[date] = lineup_data
    end
  end

  cached_lineup_data.values.flat_map do |lineup_data|
    lineup_data.map do |basic_program_info|
      series_id = basic_program_info.fetch(:seriesId)
      program_id = basic_program_info.fetch(:program).fetch(:tmsId)

      # First, grab whatever information we can from the program info we already
      # have. This often isn't complete, but if we can't fetch any more details
      # than this we'll have to make due with all that we got.
      start_time = Time.at(basic_program_info.fetch(:startTime)).getutc
      end_time = Time.at(basic_program_info.fetch(:endTime)).getutc

      title = basic_program_info.fetch(:program).fetch(:title)
      secondary_title = basic_program_info.fetch(:program).fetch(:episodeTitle)
      description = basic_program_info.fetch(:program).fetch(:shortDesc)
      image_url = "https://zap2it.tmsimg.com/assets/#{basic_program_info.fetch(:thumbnail)}.jpg"

      # Season and episode come in as either `nil` or a string integer.
      season = basic_program_info.fetch(:program).fetch(:season)
      season = season.to_i(10) unless season.nil?
      episode = basic_program_info.fetch(:program).fetch(:episode)
      episode = episode.to_i(10) unless episode.nil?

      rating = basic_program_info.fetch(:rating)

      # These don't show up at all in the basic info :(
      genres = []
      credits = []

      raw_release_year = basic_program_info.fetch(:program).fetch(:releaseYear)
      original_release_date =
        if raw_release_year.nil?
          nil
        else
          Date.parse("#{raw_release_year.rjust(4, '0')}-01-01").to_time.getutc
        end

      # Generic comes in as `"0"` or `"1"` and appears to indicate things like
      # "paid programming".
      is_generic = basic_program_info.fetch(:program).fetch(:isGeneric) == '1'
      is_movie = is_movie_id(basic_program_info.fetch(:seriesId))

      # These "bits" are special in that in the basic info they come back as
      # tags, but in the enhanced info they come back as their own individual
      # flags. We search the basic info for any tags that indicate these flags,
      # then Boolean "or" them with any that come back from the enhanced info.
      flag_tags = [
        new_tag = 'New',
        live_tag = 'Live',
        finale_tag = 'Finale',

        # Cover all our bases in case the API's spelling isn't consistent.
        premiere_tag_1 = 'Premier',
        premiere_tag_2 = 'Premiere',
      ]
      is_new = basic_program_info.fetch(:tag).include?(new_tag)
      is_live = basic_program_info.fetch(:tag).include?(live_tag)
      is_finale = basic_program_info.fetch(:tag).include?(finale_tag)
      is_premiere = (
        basic_program_info.fetch(:tag).include?(premiere_tag_1) ||
        basic_program_info.fetch(:tag).include?(premiere_tag_2)
      )

      # Omit any of the "special" tags we just checked for since they're
      # redundant if included in both places.
      #
      # NOTE: The tags at the "top level" here in the basic info are actually
      # _better_ than the tags we get from the enhanced info! The "enhanced"
      # tags come in something like `STEREO|CC` and have to be manually cleaned,
      # so we prefer the "basic" tags instead.
      tags = basic_program_info.fetch(:tag, [])
        .compact
        .reject { |t| flag_tags.include?(t) }
        .map(&:strip)
        .reject(&:empty?)

      # Now, fetch detailed program info if possible and improve what we've
      # already gathers.
      enhanced_program_info = fetch_program_details(
        series_id,
        program_id,
        cache: cache,
      )
      unless enhanced_program_info.nil?
        # We prefer the detailed version of this data if available, otherwise we
        # fall back to the "basic" version
        season = enhanced_program_info.fetch(:season, season)
        episode = enhanced_program_info.fetch(:episode, episode)

        # We "merge" these basic values with the enhanced ones.
        is_new = is_new || enhanced_program_info.fetch(:new?)
        is_live = is_live || enhanced_program_info.fetch(:live?)
        is_premiere = is_premiere || enhanced_program_info.fetch(:premiere?)
        is_finale = is_finale || enhanced_program_info.fetch(:finale?)

        # If any of these values seem to be more "substantial" than the ones we
        # got from the basic info, we'll use them instead.
        secondary_title = secondary_title || enhanced_program_info.fetch(:title)
        if (enhanced_program_info.fetch(:title) || '').length > (secondary_title || '').length
          secondary_title = enhanced_program_info.fetch(:title)
        end

        description = description || enhanced_program_info.fetch(:description)
        if (enhanced_program_info.fetch(:description) || '').length > (description || '').length
          description = enhanced_program_info.fetch(:description)
        end

        # For these, we prefer the "enhanced" version wherever available.
        original_release_date = enhanced_program_info.fetch(:original_release_date, original_release_date)
        rating = enhanced_program_info.fetch(:rating, rating)

        # These don't show up at all in the "basic" info, so we _must_ use those
        # that come back from the enhanced info.
        genres = enhanced_program_info.fetch(:genres)
        credits = enhanced_program_info.fetch(:credits)
      end

      Program.new(
        channel: channel,
        series_id: series_id,
        program_id: program_id,
        start_time: start_time,
        end_time: end_time,
        image_url: image_url,
        season: season,
        episode: episode,
        title: title,
        secondary_title: secondary_title,
        description: description,
        rating: rating,
        original_release_date: original_release_date,
        tags: tags,
        genres: genres,
        is_movie: is_movie,
        is_new: is_new,
        is_live: is_live,
        is_premiere: is_premiere,
        is_finale: is_finale,
        is_generic: is_generic,
        credits: credits,

        # TODO: Where would we find this?
        previously_shown_time: nil,
      )
    end
  end
end

# Formats the given data nicely for display in the terminal as a table and
# returns the result.
#
# No more columns than those given will be displayed. If any row contains too
# few values for the given columns, empty strings will be displayed in the
# "holes".
def display_table(
  columns, # Array<Symbol | String>
  rows, # Array<Tuple<any>>
  column_padding: 2 # Integer, the space between columns
) # String
  # Turn everything into a string and resize all the rows to be no longer than
  # the number of columns. Any "missing" columns will be omitted from the output
  # entirely.
  max_column_value_lengths = columns.map { 0 }
  prepared_rows = [columns, *rows].map do |row|
    row
      .slice(0, columns.length) # Truncate to column length
      .map(&:to_s) # Stringify contents
      .each_with_index do |value, column_index| # Update max value size
        value_length = value.length
        if max_column_value_lengths[column_index] < value_length
          max_column_value_lengths[column_index] = value_length
        end
      end
  end

  column_padder = ' ' * column_padding
  prepared_rows.each_with_index.map do |row, _index|
    row
      .each_with_index
      .map { |r, i| r.ljust(max_column_value_lengths[i]) }
      .join(column_padder)
      .strip
  end.join("\n")
end

# Returns a string for terminal output representing provider information.
def display_providers(
  country, # :USA | :CAN
  postal_code, # String
  cache: Cache.new # Cache
) # String
  providers = fetch_providers(
    country,
    postal_code,
    cache: cache,
  )

  display_table(
    %i[NAME TYPE ID],
    providers.map { |p| [p.name, p.type, p.id] },
  )
end

# Returns a string for terminal output representing the channel list for the
# given provider.
def display_channels(
  provider, # Provider
  channel_tokens: Set.new, # Enumerable<String> | nil. If non-empty, channels to display
  cache: Cache.new # Cache
) # String
  channels = fetch_channels(
    provider,
    channel_tokens: channel_tokens,
    cache: cache,
  )

  display_table(
    %i[CALL_SIGN NUMBER NAME ID],
    channels.map { |c| [c.call_sign, c.number, c.name, c.id] },
  )
end

# Returns a string for terminal output representing the program lineup for the
# given channel.
def display_lineup(
  channels, # Channel
  start_date = Time.now.getutc, # Time, inclusive, but will be truncated to its date component
  end_date = start_date, # Time, exclusive, but will be truncated to its date component
  cache: Cache.new # Cache
)
  programs = channels.flat_map do |channel|
    fetch_lineup(
      channel,
      start_date,
      end_date,
      cache: cache,
    )
  end

  date_format = '%Y-%m-%d'
  time_format = '%l:%M %p'
  display_table(
    %i[CHANNEL DATE START END TITLE],
    programs.map do |p|
      [
        p.channel.call_sign,
        p.start_time.strftime(date_format),
        p.start_time.strftime(time_format),
        p.end_time.strftime(time_format),
        p.title,
      ]
    end,
  )
end

def main!
  config = parse_config_from_args(ARGV).freeze

  # Set up logging as requested before we do anything else so we can ensure any
  # chose log settings are respected for as long as possible.
  LOG.level = config.log_level
  LOG.info("Logging configured for #{config.log_level.to_s.upcase}-level output")

  LOG.debug { "Parsed program configuration:\n#{config}" }

  $output = config.output_file
  LOG.debug("Directing standard output to #{$output}")

  cache = config.cache
  LOG.debug do
    if cache.path.nil?
      'Using in-memory cache'
    else
      "Using cache at #{cache.path}"
    end
  end

  # Output program help text.
  #
  # This is handled as the very first "mode" since it's the most important part
  # of any command; its presence anywhere in the arguments indicates the user
  # doesn't know what to do and needs our guidance!
  if config.return_help_text?
    LOG.debug('Returning program help text')

    $output.puts(config.option_parser.help)
    return
  end

  # Output program version information.
  if config.return_version_info?
    LOG.debug('Returning program version string')

    $output.puts(VERSION_INFO)
    return
  end

  # Output our XMLTV description.
  if config.return_description?
    LOG.debug('Returning XMLTV description')

    $output.puts(XMLTV_DESCRIPTION)
    return
  end

  # Output our XMLTV capabilities.
  if config.return_capabilities?
    LOG.debug('Returning XMLTV capabilities')

    XMLTV_CAPABILITIES.each do |capability|
      $output.puts(capability)
    end
    return
  end

  # Download and print out the configured lineup information.
  if config.return_providers?
    LOG.debug('Displaying providers')

    country = config.require(:country)
    postal_code = config.require(:postal_code)

    output = display_providers(
      country,
      postal_code,
      cache: cache,
    )
    $output.puts(output)
    return
  end

  # Download and print out a listing of the channels for the given provider
  # information.
  if config.return_channels?
    LOG.debug('Displaying channels')

    country = config.require(:country)
    postal_code = config.require(:postal_code)
    provider_id = config.require(:provider_id)

    provider = fetch_provider(
      country,
      postal_code,
      provider_id,
      cache: cache,
    )

    if provider.nil?
      raise ArgumentError, "No provider found for country #{country}, postal code #{postal_code}, and id #{provider_id}"
    end

    output = display_channels(
      provider,
      channel_tokens: config.channel_tokens,
      cache: cache,
    )
    $output.puts(output)
    return
  end

  # Download and print out a listing of the channel lineups for the given
  # channels and times.
  if config.return_lineup?
    LOG.debug('Displaying lineup')

    country = config.require(:country)
    postal_code = config.require(:postal_code)
    provider_id = config.require(:provider_id)
    days_to_fetch = config.require(:days_to_fetch, 'number of days to fetch')
    day_offset = config.require(:day_offset, 'number of days to offset')

    provider = fetch_provider(
      country,
      postal_code,
      provider_id,
      cache: cache,
    )

    if provider.nil?
      raise ArgumentError, "No provider found for country #{country}, postal code #{postal_code}, and id #{provider_id}"
    end

    channels = fetch_channels(
      provider,
      channel_tokens: config.channel_tokens,
      cache: cache,
    )

    # Obey the offset and span values we were given. Note that we re-truncate
    # the end date to the prior date so that it'll be inclusive rather than
    # exclusive, as our offset and days-to-fetch values require.
    now = truncate_time(Time.now.getutc, TimeInterval::DAYS)
    start_date = now + (day_offset * TimeInterval::DAYS)
    end_date = truncate_time(
      start_date + (days_to_fetch * TimeInterval::DAYS) - 1,
      TimeInterval::DAYS,
    )

    output = display_lineup(
      channels,
      start_date,
      end_date,
      cache: cache,
    )
    $output.puts(output)
    return
  end

  # The default action is always to output the XMLTV XML described at
  # https://github.com/XMLTV/xmltv/blob/80e893e0b6c77224f2ed353a0fb577e2f82c69d4/xmltv.dtd.
  # To do this, we need to fetch all the requisite channels and providers.
  LOG.debug('Outputting XML')
  country = config.require(:country)
  postal_code = config.require(:postal_code)
  provider_id = config.require(:provider_id)
  days_to_fetch = config.require(:days_to_fetch, 'number of days to fetch')
  day_offset = config.require(:day_offset, 'number of days to offset')

  provider = fetch_provider(
    country,
    postal_code,
    provider_id,
    cache: cache,
  )

  if provider.nil?
    raise ArgumentError, "No provider found for country #{country}, postal code #{postal_code}, and id #{provider_id}"
  end

  channels = fetch_channels(
    provider,
    channel_tokens: config.channel_tokens,
    cache: cache,
  )

  # Obey the offset and span values we were given. Note that we re-truncate
  # the end date to the prior date so that it'll be inclusive rather than
  # exclusive, as our offset and days-to-fetch values require.
  now = truncate_time(Time.now.getutc, TimeInterval::DAYS)
  start_date = now + (day_offset * TimeInterval::DAYS)
  end_date = truncate_time(
    start_date + (days_to_fetch * TimeInterval::DAYS) - 1,
    TimeInterval::DAYS,
  )

  programs = channels.flat_map do |channel|
    fetch_lineup(
      channel,
      start_date,
      end_date,
      cache: cache,
    )
  end

  # Generate and write the channel and program XML to the output stream.
  $output.puts('<?xml version="1.0" encoding="utf-8"?>')
  $output.puts(
    Xml.new(
      :tv,
      {
        source_info_url: 'https://tvlistings.zap2it.com',
        source_info_name: 'zap2it',
        generator_info_name: PROGRAM_NAME,
        generator_info_url: 'https://github.com/jasontbradshaw/tv_grab_zap2it',
      },
      *channels.map(&:to_xml),
      *programs.map(&:to_xml),
    ),
  )
rescue StandardError => e
  # If we explode for any reason, exit with an error status and log the error
  # appropriately.
  LOG.fatal(e)

  # Re-raise the error if we're in debug mode. This gets us nice stack trace
  # information.
  raise if LOG.debug?

  exit 1
ensure
  # Always attempt to persist the cache once we're done, assuming it got
  # initialized.
  #
  # We don't have to worry about some partially-valid state since the cache
  # doesn't store entries that generate an exception during population, meaning
  # that whatever _does_ end up in the cache was at least valid enough to have
  # been generated by the code.
  if cache.nil?
    LOG.debug("Unable to persist a cache that doesn't exist")
  else
    cache.persist!
  end
end

main! if __FILE__ == $0
